{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Machine Learning to Predict Probability of a Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heart disease is not just the number one cause of death in Malaysia, it was also the number one cause of death worldwide. It affects both male and female. Everyone knows someone who had a heart issue. Lots of research had been invested into the possible causes of a heart disease. Machine learning could contribute in helping to reduce this number one killer.\n",
    "\n",
    "This project will take the dataset, train them using machine learning algorithm and predict the probability of a patient having a heart disease. A label has been given in the dataset:-\n",
    "* 0: Heart disease is not present\n",
    "* 1: Heart disease present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the modules that will be used\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import the data\n",
    "\n",
    "# for training our model\n",
    "train_values = pd.read_csv('train_values.csv', index_col='patient_id')\n",
    "train_labels = pd.read_csv('train_labels.csv', index_col='patient_id')\n",
    "\n",
    "#for testing the model\n",
    "test_values = pd.read_csv('test_values.csv', index_col='patient_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is provided courtesy of Cleveland Heart Disease Database from a competition organised by drivendata. The dataset collects various measurements on health and cardiovascular statistics. Patient's identities are anonymous. \n",
    "\n",
    "Dataset downnload: [drivendata](https://www.drivendata.org/competitions/54/machine-learning-with-a-heart/page/107/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for training data length\n",
    "\n",
    "len(train_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for testing data length\n",
    "\n",
    "len (test_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has been split into training data and test data. Training data has 180 values, while the test data has 90 values. There are 14 columns in the training dataset, where patient_id serves as an identifier. Below are the attributes information  and type of the remaining 13 columns. \n",
    "\n",
    "From: [drivendata](https://www.drivendata.org/competitions/54/machine-learning-with-a-heart/page/109/)\n",
    "\n",
    "Attribute Information: \n",
    "------------------------ \n",
    "1. slope_of_peak_exercise_st_segment (type: int): the slope of the peak exercise ST segment, an electrocardiography read out indicating quality of blood flow to the heart\n",
    "2. thal (type: categorical): results of thallium stress test measuring blood flow to the heart, with possible values normal, fixed_defect, reversible_defect\n",
    "3. resting_blood_pressure (type: int): resting blood pressure\n",
    "4. chest_pain_type (type: int): chest pain type (4 values)\n",
    "5. num_major_vessels (type: int): number of major vessels (0-3) colored by flourosopy\n",
    "6. fasting_blood_sugar_gt_120_mg_per_dl (type: binary): fasting blood sugar > 120 mg/dl\n",
    "7. resting_ekg_results (type: int): resting electrocardiographic results (values 0,1,2)\n",
    "8. serum_cholesterol_mg_per_dl (type: int): serum cholestoral in mg/dl\n",
    "9. oldpeak_eq_st_depression (type: float): oldpeak = ST depression induced by exercise relative to rest, a measure of abnormality in electrocardiograms\n",
    "10. sex (type: binary): 0: female, 1: male\n",
    "11. age (type: int): age in years\n",
    "12. max_heart_rate_achieved (type: int): maximum heart rate achieved (beats per minute)\n",
    "13. exercise_induced_angina (type: binary): exercise-induced chest pain (0: False, 1: True)\n",
    "\n",
    "--*labels: 1: Heart disease present. 0: Heart disease is not present\n",
    "There are no missing values in this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.550000</td>\n",
       "      <td>131.311111</td>\n",
       "      <td>3.155556</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.161111</td>\n",
       "      <td>1.050000</td>\n",
       "      <td>249.211111</td>\n",
       "      <td>1.010000</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>54.811111</td>\n",
       "      <td>149.483333</td>\n",
       "      <td>0.316667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.618838</td>\n",
       "      <td>17.010443</td>\n",
       "      <td>0.938454</td>\n",
       "      <td>0.969347</td>\n",
       "      <td>0.368659</td>\n",
       "      <td>0.998742</td>\n",
       "      <td>52.717969</td>\n",
       "      <td>1.121357</td>\n",
       "      <td>0.464239</td>\n",
       "      <td>9.334737</td>\n",
       "      <td>22.063513</td>\n",
       "      <td>0.466474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>213.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>245.500000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>281.250000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>166.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       slope_of_peak_exercise_st_segment  resting_blood_pressure  \\\n",
       "count                         180.000000              180.000000   \n",
       "mean                            1.550000              131.311111   \n",
       "std                             0.618838               17.010443   \n",
       "min                             1.000000               94.000000   \n",
       "25%                             1.000000              120.000000   \n",
       "50%                             1.000000              130.000000   \n",
       "75%                             2.000000              140.000000   \n",
       "max                             3.000000              180.000000   \n",
       "\n",
       "       chest_pain_type  num_major_vessels  \\\n",
       "count       180.000000         180.000000   \n",
       "mean          3.155556           0.694444   \n",
       "std           0.938454           0.969347   \n",
       "min           1.000000           0.000000   \n",
       "25%           3.000000           0.000000   \n",
       "50%           3.000000           0.000000   \n",
       "75%           4.000000           1.000000   \n",
       "max           4.000000           3.000000   \n",
       "\n",
       "       fasting_blood_sugar_gt_120_mg_per_dl  resting_ekg_results  \\\n",
       "count                            180.000000           180.000000   \n",
       "mean                               0.161111             1.050000   \n",
       "std                                0.368659             0.998742   \n",
       "min                                0.000000             0.000000   \n",
       "25%                                0.000000             0.000000   \n",
       "50%                                0.000000             2.000000   \n",
       "75%                                0.000000             2.000000   \n",
       "max                                1.000000             2.000000   \n",
       "\n",
       "       serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression         sex  \\\n",
       "count                   180.000000                180.000000  180.000000   \n",
       "mean                    249.211111                  1.010000    0.688889   \n",
       "std                      52.717969                  1.121357    0.464239   \n",
       "min                     126.000000                  0.000000    0.000000   \n",
       "25%                     213.750000                  0.000000    0.000000   \n",
       "50%                     245.500000                  0.800000    1.000000   \n",
       "75%                     281.250000                  1.600000    1.000000   \n",
       "max                     564.000000                  6.200000    1.000000   \n",
       "\n",
       "              age  max_heart_rate_achieved  exercise_induced_angina  \n",
       "count  180.000000               180.000000               180.000000  \n",
       "mean    54.811111               149.483333                 0.316667  \n",
       "std      9.334737                22.063513                 0.466474  \n",
       "min     29.000000                96.000000                 0.000000  \n",
       "25%     48.000000               132.000000                 0.000000  \n",
       "50%     55.000000               152.000000                 0.000000  \n",
       "75%     62.000000               166.250000                 1.000000  \n",
       "max     77.000000               202.000000                 1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Describe the data\n",
    "\n",
    "display(train_values.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum value for serum_cholesterol_mg_per_dl is 564.000000. I didn't know if this is an actual outlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rv6siv</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>564</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            slope_of_peak_exercise_st_segment               thal  \\\n",
       "patient_id                                                         \n",
       "rv6siv                                      2  reversible_defect   \n",
       "\n",
       "            resting_blood_pressure  chest_pain_type  num_major_vessels  \\\n",
       "patient_id                                                               \n",
       "rv6siv                         115                3                  0   \n",
       "\n",
       "            fasting_blood_sugar_gt_120_mg_per_dl  resting_ekg_results  \\\n",
       "patient_id                                                              \n",
       "rv6siv                                         0                    2   \n",
       "\n",
       "            serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  sex  age  \\\n",
       "patient_id                                                                    \n",
       "rv6siv                              564                       1.6    0   67   \n",
       "\n",
       "            max_heart_rate_achieved  exercise_induced_angina  \n",
       "patient_id                                                    \n",
       "rv6siv                          160                        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding the outlier\n",
    "\n",
    "train_values[train_values.serum_cholesterol_mg_per_dl == 564.000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cholesterol level is on high end, especially any value exceeded 240mg/dl is considered ['very high'](https://my.clevelandclinic.org/health/articles/11920-cholesterol-numbers-what-do-they-mean). However, the highest cholesterol level ever recorded is 3165 mg/dl, [Guiness Book of Record](http://www.guinnessworldrecords.com/world-records/highest-triglyceride-level/), and that value is definitely an outlier. With this information, I shall keep this outlier in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "I would like to create a attribute called age-range. But before that, I would like an overview of the age distribution for train_values dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Frequency')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAGd1JREFUeJzt3Xu4HXV97/H3hwBy1XDZYLjELUq5\nqBAwIN4xiCIoYosopYoWjT3Fo57WS+Rpj1jFQqvSgpcaC4qoyE0KAlYDRSl9esAAAYGAoEYJBBLk\nGkSQ8Dl/zG/T5WZf1t5k1srO7/N6nvWsNbNm1nx/e629PjO/mTUj20RERL3W6XcBERHRXwmCiIjK\nJQgiIiqXIIiIqFyCICKicgmCiIjKJQjiaZP0fUlH9ruONkl6paRb+l0HgKS/lfQvq3vaXpG0VNK+\nvZ43RpcgmMIk/UjSfZKe0fIy3jNs3L6Slg4N236D7dO6eC1Len4bdbbN9n/a3mmi80k6RtLKcvud\npFUdwzdOspZP2f6L1T3tREhat7yfg6v7taP3EgRTVPkHfCVg4OC+FrMGkLRuv2sYie3P2N7E9ibA\nXwD/PTRs+wXDp19T2xFrtwTB1PVO4P8BXwf+oFtG0haSvifpQUk/kfRpSVd0PL+zpAWS7pV0i6TD\nnk4hnVsNkp4v6ceSHpB0j6Qzy/jLy+TXlbXht5Xx75V0W6nlAknbdLzu60p9D0j6UnndoeW8S9J/\nSTpR0r3AsZKeJ+k/JP2mLPtbkqZ3vN4SSR+RdL2khyWdImnr0rX1kKRLJG02Shv/YCuovNaHy2s9\nIOlMSRtM4m83tGb9l5JuA24u479QukGG3sOXdczzaUlf7/h7W9I7y/QrJM2b5LQbSfqmpPsl3SRp\nnqQlk2jTjpIu63gfTpf0rGGTvUTS4rJFe0rnVq2kgyVdV+q4QtILR1nOPpKuKX+juyX940RrjUaC\nYOp6J/Ctcnu9pK07nvsi8DDwbJqQeDIoJG0MLAC+DWwFHA58SdJT1k4n6VPAD4HNgO2AkwFsv6o8\nv3tZGz5T0hzg74HDgBnAr4DvlDq3BM4BPg5sAdwCvIw/9BLgF6UdxwEqr7cNsAuwPXDssHn+BNgf\n+CPgTcD3gWOALWn+Hz4wgbYeBhwAPBfYDXjXBOYd7mBgL+BFZfjK8pqb0/wdztbYXYAvA54PvB74\npKQdJzHt39H87QbLc382qZY078Onad7TXYEdgL8dNs0RNO/DjsALaN5nJO0FfBV4D837fipwvqT1\nR1jOycA/2n5mac85k6y3egmCKUjSK4DnAGfZvhr4OfCn5blpNF92n7D9W9s3AZ39928Eltj+mu3H\nbV8DnAscOsYiTyprZ/dLuh+4cIxpf19q28b272xfMca0RwCn2r7G9qM0XwYvVdPtdSBwo+3v2n4c\nOAm4a9j8d9o+ubTjEdu32V5g+1HbK4DPA68eNs/Jtu+2fQfwn8CVtq8tyz8P2GOMeoc7yfadtu8F\nvgfMmsC8w33G9n22HwGwfbrte0vb/wEY+rIbzbHl730NcCOw+ySmPQw4zvb9tm8HvjCZhtj+me1L\nbT9mezlwIk99H06yvdT2PcBnaFZIAOYCX7L9E9urbJ9axu81wqJ+D+woaQvbD9m+cjL1RoJgqjoS\n+GH5J4Jm7X5orX8AWBe4vWP6zsfPodks7/xiP4Jm62E0H7A9fehGEyaj+SjNGuFVkm6U9OdjTLsN\nzVYAALZXAr8Bti3P3d7xnIGlw+bvbBeStpL0HUl3SHoQ+CbNmn6nuzsePzLC8CZj1DtcZzD9doLz\nDje8LR+VdLOkB4D7gI15alueZLvrWsaYdgajf266JunZks7qeB++zlNr73ztX9G839B8Pj827PM5\ng+YzMdy7abY4bpF0laQDJ1NvNF8YMYVI2pBmzW2apKF/6GcA0yXtDtwAPE7TLfOz8vz2HS9xO/Bj\n2/u3UV/5knlvqfUVwCWSLrd92wiT30nzj0+ZfmOa7oA7gGU0bRh6Tp3DQ4sbNvz3Zdxutn8j6RAm\nuVbbB0+2RdJrgL8C9gNuKqMfoAnYNt3F6J+biTgBeBR4ke17JR0KfHbYNJ2vPZPmswDN5/OTtk8Y\nbyG2bwHeLmkd4K3AuZI2s/27SdZdrWwRTD2HAKto1oRmldsuNN0c77S9Cvguzc7TjSTtTLM/YciF\nwB9Jeoek9cptL0m7rI7iJL1V0tAX9n00X3CryvDdNP3FQ74NvFvSrNL//RmarpolwEXAiyQdouZI\nmqMZe6sFYFNgJXC/pG2Bj6yONvXBpjRhfg+wHs1+jo17sNyzgGMkTS/v4dFdzPMMSRt03KbR1P8w\n8ICk7YEPjzDf+yVtK2kLmi7BM8v4+cDR5TMpSZtIelNZSfgD5TO8pe0naILSwBMTbnUkCKagI4Gv\n2f617buGbjRrvkeUL833A8+iWcM7HTiDZg0N2w8BrwPeTrMWdhfNGtzq+i3CXsCVklYCFwAftP3L\n8tyxwGllk/8w25fS7EQ8l2YL4HmlLkq311tp+sd/QxN8C4faMYpPAnvSfClcRBOIU9HFwCXArcAS\n4EGav0/bPkET1ktodvifxdh/b2iOcnqk4/aO8jp707wPF9C8v8OdQdPGn9McCPAZgNLP/7+AL9Os\nSPyM0XdaHwgslvQQzRbH22w/Nn4zYzjlwjRrP0knAM+2PWV//Vs2/5cCR9i+rN/11EDS/wYOsb1f\nv2uJdmWLYC2k5ncCu5VN672Bo2iOiJlSJL2+dFM8g+YQT9H8diJaULpqXiZpndJV+H+Ygp+bmLjs\nLF47bUqz6b0NsBz4HHB+XyuanJfS7EdYn2an6SFDh1dGK55Bcwz/IE23zBnAV/pZUPRGuoYiIiqX\nrqGIiMpNia6hLbfc0oODg/0uIyJiSrn66qvvsT0w3nStBYGaE3BdTtPvuC5wju1PqDkB1qtpDi0D\neJftRWO91uDgIAsXLmyr1IiItZKkX40/VbtbBI8Cc2yvlLQecIWk75fnPmI7J4iKiFgDtBYE5dww\nK8vgeuWWPdMREWuYVncWS5omaRHNIYwLOs4OeJya87ifOM6pdSMiomWtBkE5jewsmhNZ7V0uMPFx\nYGeaUxFsDnxspHklzZW0UNLCFStWtFlmRETVenL4qO37gR8BB9he5sajwNdozkky0jzzbc+2PXtg\nYNyd3hERMUmtBYGkAZXLBJZTJ78WuFnSjDJONGfSvKGtGiIiYnxtHjU0g+ZMk9NoAucs2xequabs\nAM15YxbRXNA7IiL6pM2jhq5nhMv+2Z7T1jIjImLicoqJiIjKTYlTTESsqQbnXdS3ZS85/qC+LTvW\nLtkiiIioXIIgIqJyCYKIiMolCCIiKpcgiIioXI4aipii+nXEUo5WWvtkiyAionIJgoiIyiUIIiIq\nlyCIiKhcgiAionIJgoiIyiUIIiIqlyCIiKhcgiAionIJgoiIyiUIIiIqlyCIiKhcgiAionIJgoiI\nyrUWBJI2kHSVpOsk3Sjpk2X8cyVdKelWSWdKWr+tGiIiYnxtbhE8CsyxvTswCzhA0j7ACcCJtncE\n7gOOarGGiIgYR2tB4MbKMrheuRmYA5xTxp8GHNJWDRERMb5Wr1AmaRpwNfB84IvAz4H7bT9eJlkK\nbDvKvHOBuQAzZ85ss8yImIB+XRkNcnW0trS6s9j2KtuzgO2AvYFdRppslHnn255te/bAwECbZUZE\nVK0nRw3Zvh/4EbAPMF3S0JbIdsCdvaghIiJG1uZRQwOSppfHGwKvBRYDlwGHlsmOBM5vq4aIiBhf\nm/sIZgCnlf0E6wBn2b5Q0k3AdyR9GrgWOKXFGiIiYhytBYHt64E9Rhj/C5r9BRERsQbIL4sjIiqX\nIIiIqFyCICKicgmCiIjKJQgiIiqXIIiIqFyCICKicgmCiIjKJQgiIiqXIIiIqFyCICKicgmCiIjK\nJQgiIiqXIIiIqFyCICKicgmCiIjKJQgiIiqXIIiIqFyCICKicgmCiIjKJQgiIirXWhBI2l7SZZIW\nS7pR0gfL+GMl3SFpUbkd2FYNERExvnVbfO3Hgb+2fY2kTYGrJS0oz51o+7MtLjsiIrrUWhDYXgYs\nK48fkrQY2Lat5UVExOT0ZB+BpEFgD+DKMur9kq6XdKqkzXpRQ0REjKzNriEAJG0CnAt8yPaDkr4M\nfApwuf8c8OcjzDcXmAswc+bMtsuM1WBw3kV9W/aS4w/q27IjprpWtwgkrUcTAt+y/V0A23fbXmX7\nCeCrwN4jzWt7vu3ZtmcPDAy0WWZERNXaPGpIwCnAYtuf7xg/o2OytwA3tFVDRESMr82uoZcD7wB+\nKmlRGXcMcLikWTRdQ0uA97VYQ0REjKPNo4auADTCUxe3tcyIiJi4/LI4IqJyCYKIiMolCCIiKpcg\niIioXIIgIqJyCYKIiMolCCIiKpcgiIioXIIgIqJyCYKIiMolCCIiKpcgiIioXIIgIqJyrV+hLKIX\n+nl1tIiprqstAkkvbLuQiIjoj267hv5F0lWS/lLS9FYrioiInuoqCGy/AjgC2B5YKOnbkvZvtbKI\niOiJrncW274V+BvgY8CrgZMk3Szpj9sqLiIi2tftPoLdJJ0ILAbmAG+yvUt5fGKL9UVERMu6PWro\nC8BXgWNsPzI00vadkv6mlcoiIqInug2CA4FHbK8CkLQOsIHt39o+vbXqIiKidd3uI7gE2LBjeKMy\nLiIiprhug2AD2yuHBsrjjcaaQdL2ki6TtFjSjZI+WMZvLmmBpFvL/WaTLz8iIp6uboPgYUl7Dg1I\nejHwyBjTAzwO/HXZqbwPcLSkXYF5wKW2dwQuLcMREdEn3e4j+BBwtqQ7y/AM4G1jzWB7GbCsPH5I\n0mJgW+DNwL5lstOAH9EckhoREX3QVRDY/omknYGdAAE32/59twuRNAjsAVwJbF1CAtvLJG01yjxz\ngbkAM2fO7HZRERExQRM56dxewGCZZw9J2P7GeDNJ2gQ4F/iQ7QcldbUw2/OB+QCzZ8/2BOqMiIgJ\n6CoIJJ0OPA9YBKwqow2MGQSS1qMJgW/Z/m4ZfbekGWVrYAawfFKVR0TEatHtFsFsYFfbXa+Zq1n1\nPwVYbPvzHU9dABwJHF/uz+/2NSMiYvXr9qihG4BnT/C1Xw68A5gjaVG5HUgTAPtLuhXYvwxHRESf\ndLtFsCVwk6SrgEeHRto+eLQZbF9Bs2N5JPt1XWFERLSq2yA4ts0iIiKif7o9fPTHkp4D7Gj7Ekkb\nAdPaLS0iInqh29NQvxc4B/hKGbUt8G9tFRUREb3T7c7io2l2/j4IT16kZsQfgkVExNTSbRA8avux\noQFJ69L8jiAiIqa4boPgx5KOATYs1yo+G/hee2VFRESvdBsE84AVwE+B9wEX01y/OCIiprhujxp6\nguZSlV9tt5yIiOi1bs819EtG2Cdge4fVXlFERPTURM41NGQD4K3A5qu/nIiI6LWu9hHY/k3H7Q7b\n/wTMabm2iIjogW67hvbsGFyHZgth01YqioiInuq2a+hzHY8fB5YAh632amK1GJx3Ub9LiIgppNuj\nhl7TdiEREdEf3XYN/dVYzw+78ExEREwhEzlqaC+aq4sBvAm4HLi9jaIiIqJ3JnJhmj1tPwQg6Vjg\nbNvvaauwiIjojW5PMTETeKxj+DFgcLVXExERPdftFsHpwFWSzqP5hfFbgG+0VlVERPRMt0cNHSfp\n+8Ary6h32762vbIiIqJXuu0aAtgIeND2PwNLJT23pZoiIqKHur1U5SeAjwEfL6PWA745zjynSlou\n6YaOccdKukPSonI7cLKFR0TE6tHtFsFbgIOBhwFs38n4p5j4OnDACONPtD2r3C7uttCIiGhHt0Hw\nmG1TTkUtaePxZrB9OXDv06gtIiJ6oNsgOEvSV4Dpkt4LXMLkL1LzfknXl66jzUabSNJcSQslLVyx\nYsUkFxUREePp9jTUnwXOAc4FdgL+r+2TJ7G8LwPPA2YBy/jDk9kNX+Z827Ntzx4YGJjEoiIiohvj\nHj4qaRrwA9uvBRY8nYXZvrvjdb8KXPh0Xi8iIp6+cbcIbK8CfivpWU93YZJmdAy+BbhhtGkjIqI3\nuv1l8e+An0paQDlyCMD2B0abQdIZwL7AlpKWAp8A9pU0i2an8xLgfZMrOyIiVpdug+Cicuua7cNH\nGH3KRF4jIiLaN2YQSJpp+9e2T+tVQRER0Vvj7SP4t6EHks5tuZaIiOiD8YJAHY93aLOQiIjoj/GC\nwKM8joiItcR4O4t3l/QgzZbBhuUxZdi2n9lqdRER0boxg8D2tF4VEhER/TGR6xFERMRaKEEQEVG5\nBEFEROUSBBERlUsQRERULkEQEVG5BEFEROUSBBERlUsQRERULkEQEVG5BEFEROUSBBERlUsQRERU\nrttrFkdE9N3gvAldOn21WXL8QX1Zbq9kiyAionIJgoiIyrUWBJJOlbRc0g0d4zaXtEDSreV+s7aW\nHxER3Wlzi+DrwAHDxs0DLrW9I3BpGY6IiD5qLQhsXw7cO2z0m4HTyuPTgEPaWn5ERHSn1/sItra9\nDKDcbzXahJLmSlooaeGKFSt6VmBERG3W2J3Ftufbnm179sDAQL/LiYhYa/U6CO6WNAOg3C/v8fIj\nImKYXgfBBcCR5fGRwPk9Xn5ERAzT5uGjZwD/Dewkaamko4Djgf0l3QrsX4YjIqKPWjvFhO3DR3lq\nv7aWGRERE7fG7iyOiIjeSBBERFQuQRARUbkEQURE5RIEERGVSxBERFQuQRARUbkEQURE5RIEERGV\nSxBERFQuQRARUbkEQURE5RIEERGVSxBERFQuQRARUbkEQURE5RIEERGVSxBERFQuQRARUbkEQURE\n5RIEERGVW7cfC5W0BHgIWAU8bnt2P+qIiIg+BUHxGtv39HH5ERFBuoYiIqrXry0CAz+UZOArtucP\nn0DSXGAuwMyZM3tc3uoxOO+ifpcQETGufm0RvNz2nsAbgKMlvWr4BLbn255te/bAwEDvK4yIqERf\ngsD2neV+OXAesHc/6oiIiD4EgaSNJW069Bh4HXBDr+uIiIhGP/YRbA2cJ2lo+d+2/e99qCMiIuhD\nENj+BbB7r5cbEREjy+GjERGVSxBERFQuQRARUbkEQURE5RIEERGVSxBERFQuQRARUbkEQURE5RIE\nERGVSxBERFQuQRARUbkEQURE5RIEERGV6+fF6yMipoR+XnZ2yfEHtb6MbBFERFQuQRARUbkEQURE\n5RIEERGVSxBERFRurT9qqJ97+yMipoJsEUREVC5BEBFRub4EgaQDJN0i6TZJ8/pRQ0RENHoeBJKm\nAV8E3gDsChwuadde1xEREY1+bBHsDdxm+xe2HwO+A7y5D3VERAT9OWpoW+D2juGlwEuGTyRpLjC3\nDK6UdEsLtWwJ3NPC604FaXu9am7/lGu7Tnhasz+nm4n6EQQaYZyfMsKeD8xvtRBpoe3ZbS5jTZW2\n19l2qLv9Nbd9LP3oGloKbN8xvB1wZx/qiIgI+hMEPwF2lPRcSesDbwcu6EMdERFBH7qGbD8u6f3A\nD4BpwKm2b+x1HUWrXU9ruLS9XjW3v+a2j0r2U7rnIyKiIvllcURE5RIEERGVqyIIJG0g6SpJ10m6\nUdIny/jnSrpS0q2Sziw7r9dKkqZJulbShWW4prYvkfRTSYskLSzjNpe0oLR/gaTN+l1nGyRNl3SO\npJslLZb00oravlN5z4duD0r6UC3tn4gqggB4FJhje3dgFnCApH2AE4ATbe8I3Acc1cca2/ZBYHHH\ncE1tB3iN7Vkdx5DPAy4t7b+0DK+N/hn4d9s7A7vTfAaqaLvtW8p7Pgt4MfBb4Dwqaf9EVBEEbqws\ng+uVm4E5wDll/GnAIX0or3WStgMOAv61DItK2j6GN9O0G9bS9kt6JvAq4BQA24/Zvp8K2j6C/YCf\n2/4VdbZ/TFUEATzZNbIIWA4sAH4O3G/78TLJUprTX6yN/gn4KPBEGd6CetoOTej/UNLV5dQlAFvb\nXgZQ7rfqW3Xt2QFYAXytdAv+q6SNqaPtw70dOKM8rrH9Y6omCGyvKpuI29Gc+G6XkSbrbVXtk/RG\nYLntqztHjzDpWtf2Di+3vSfNGW+PlvSqfhfUI+sCewJftr0H8DAVdoOU/V8HA2f3u5Y1VTVBMKRs\nGv8I2AeYLmnoR3Vr66kuXg4cLGkJzZle59BsIdTQdgBs31nul9P0Ee8N3C1pBkC5X96/CluzFFhq\n+8oyfA5NMNTQ9k5vAK6xfXcZrq3946oiCCQNSJpeHm8IvJZmp9llwKFlsiOB8/tTYXtsf9z2drYH\naTaP/8P2EVTQdgBJG0vadOgx8DrgBprTmhxZJlsr22/7LuB2STuVUfsBN1FB24c5nP/pFoL62j+u\nKn5ZLGk3mp1C02jC7yzbfydpB5q15M2Ba4E/s/1o/yptl6R9gQ/bfmMtbS/tPK8Mrgt82/ZxkrYA\nzgJmAr8G3mr73j6V2RpJs2gOElgf+AXwbsr/AGt52wEkbURz2vsdbD9QxlXx3k9EFUEQERGjq6Jr\nKCIiRpcgiIioXIIgIqJyCYKIiMolCCIiKpcgiBiHpLdIsqSd+11LRBsSBBHjOxy4guYHeRFrnQRB\nxBgkbUJzmo6jKEEgaR1JXyrXtrhQ0sWSDi3PvVjSj8sJ7n4wdCqDiDVZgiBibIfQnM//Z8C9kvYE\n/hgYBF4EvAd4KYCk9YCTgUNtvxg4FTiuH0VHTMS6408SUbXDaU7SB80pOQ6nuZ7F2bafAO6SdFl5\nfifghcCC5pIPTAOW9bbciIlLEESMopyTZg7wQkmm+WI3/3PuoqfMAtxo+6U9KjFitUjXUMToDgW+\nYfs5tgdtbw/8ErgH+JOyr2BrYN8y/S3AgKQnu4okvaAfhUdMRIIgYnSH89S1/3OBbWjO9X8D8BXg\nSuAB24/RhMcJkq4DFgEv6125EZOTs49GTIKkTWyvLN1HV9FcBe2uftcVMRnZRxAxOReWix2tD3wq\nIRBTWbYIIiIql30EERGVSxBERFQuQRARUbkEQURE5RIEERGV+//nYbfy1pmy8gAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xbc98dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#histogram on age\n",
    "\n",
    "plt.hist(train_values['age'])\n",
    "plt.title(\"Age Histogram in Training Labels\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the age range falls around 50 to 70.  29 is the youngest age found in this dataset while 77 is the oldest. This new attribute will group the age as per below:-\n",
    "\n",
    "* 21 to 40\n",
    "* 41 to 60\n",
    "* 61 to 80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0z64un</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryoo3j</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt1s1x</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2xjde</th>\n",
       "      <td>1</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyt4ek</th>\n",
       "      <td>3</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ldukkw</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2gbyh9</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>258</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daa9kp</th>\n",
       "      <td>2</td>\n",
       "      <td>fixed_defect</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>276</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3nwy2n</th>\n",
       "      <td>3</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>326</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1r508r</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ldg4b9</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>302</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xc17yq</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mpggsq</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zlyac8</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>236</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f06u72</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2fv3rc</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qyrkxn</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>234</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237mql</th>\n",
       "      <td>1</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mc750a</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30v796</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            slope_of_peak_exercise_st_segment               thal  \\\n",
       "patient_id                                                         \n",
       "0z64un                                      1             normal   \n",
       "ryoo3j                                      2             normal   \n",
       "yt1s1x                                      1             normal   \n",
       "l2xjde                                      1  reversible_defect   \n",
       "oyt4ek                                      3  reversible_defect   \n",
       "ldukkw                                      1             normal   \n",
       "2gbyh9                                      2  reversible_defect   \n",
       "daa9kp                                      2       fixed_defect   \n",
       "3nwy2n                                      3  reversible_defect   \n",
       "1r508r                                      2             normal   \n",
       "ldg4b9                                      2             normal   \n",
       "xc17yq                                      1             normal   \n",
       "mpggsq                                      1             normal   \n",
       "zlyac8                                      2             normal   \n",
       "f06u72                                      2  reversible_defect   \n",
       "2fv3rc                                      2  reversible_defect   \n",
       "qyrkxn                                      2             normal   \n",
       "237mql                                      1  reversible_defect   \n",
       "mc750a                                      1             normal   \n",
       "30v796                                      1             normal   \n",
       "\n",
       "            resting_blood_pressure  chest_pain_type  num_major_vessels  \\\n",
       "patient_id                                                               \n",
       "0z64un                         128                2                  0   \n",
       "ryoo3j                         110                3                  0   \n",
       "yt1s1x                         125                4                  3   \n",
       "l2xjde                         152                4                  0   \n",
       "oyt4ek                         178                1                  0   \n",
       "ldukkw                         130                3                  0   \n",
       "2gbyh9                         150                4                  2   \n",
       "daa9kp                         150                4                  1   \n",
       "3nwy2n                         170                4                  0   \n",
       "1r508r                         120                3                  0   \n",
       "ldg4b9                         120                4                  0   \n",
       "xc17yq                         140                4                  0   \n",
       "mpggsq                         140                3                  0   \n",
       "zlyac8                         138                4                  0   \n",
       "f06u72                         120                1                  0   \n",
       "2fv3rc                         144                4                  0   \n",
       "qyrkxn                         130                2                  0   \n",
       "237mql                         130                4                  1   \n",
       "mc750a                         130                2                  0   \n",
       "30v796                         136                2                  2   \n",
       "\n",
       "            fasting_blood_sugar_gt_120_mg_per_dl  resting_ekg_results  \\\n",
       "patient_id                                                              \n",
       "0z64un                                         0                    2   \n",
       "ryoo3j                                         0                    0   \n",
       "yt1s1x                                         0                    2   \n",
       "l2xjde                                         0                    0   \n",
       "oyt4ek                                         0                    2   \n",
       "ldukkw                                         0                    0   \n",
       "2gbyh9                                         0                    2   \n",
       "daa9kp                                         0                    2   \n",
       "3nwy2n                                         0                    2   \n",
       "1r508r                                         0                    0   \n",
       "ldg4b9                                         0                    2   \n",
       "xc17yq                                         0                    0   \n",
       "mpggsq                                         0                    0   \n",
       "zlyac8                                         0                    2   \n",
       "f06u72                                         0                    0   \n",
       "2fv3rc                                         0                    2   \n",
       "qyrkxn                                         0                    2   \n",
       "237mql                                         0                    0   \n",
       "mc750a                                         0                    2   \n",
       "30v796                                         1                    2   \n",
       "\n",
       "            serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  sex  age  \\\n",
       "patient_id                                                                    \n",
       "0z64un                              308                       0.0    1   45   \n",
       "ryoo3j                              214                       1.6    0   54   \n",
       "yt1s1x                              304                       0.0    1   77   \n",
       "l2xjde                              223                       0.0    1   40   \n",
       "oyt4ek                              270                       4.2    1   59   \n",
       "ldukkw                              180                       0.0    1   42   \n",
       "2gbyh9                              258                       2.6    0   60   \n",
       "daa9kp                              276                       0.6    1   57   \n",
       "3nwy2n                              326                       3.4    1   59   \n",
       "1r508r                              219                       1.6    0   50   \n",
       "ldg4b9                              302                       0.4    1   66   \n",
       "xc17yq                              226                       0.0    1   42   \n",
       "mpggsq                              335                       0.0    1   64   \n",
       "zlyac8                              236                       0.2    0   45   \n",
       "f06u72                              231                       3.8    1   38   \n",
       "2fv3rc                              200                       0.9    1   50   \n",
       "qyrkxn                              234                       0.6    0   45   \n",
       "237mql                              253                       1.4    1   60   \n",
       "mc750a                              204                       0.0    1   29   \n",
       "30v796                              319                       0.0    0   58   \n",
       "\n",
       "            max_heart_rate_achieved  exercise_induced_angina  \n",
       "patient_id                                                    \n",
       "0z64un                          170                        0  \n",
       "ryoo3j                          158                        0  \n",
       "yt1s1x                          162                        1  \n",
       "l2xjde                          181                        0  \n",
       "oyt4ek                          145                        0  \n",
       "ldukkw                          150                        0  \n",
       "2gbyh9                          157                        0  \n",
       "daa9kp                          112                        1  \n",
       "3nwy2n                          140                        1  \n",
       "1r508r                          158                        0  \n",
       "ldg4b9                          151                        0  \n",
       "xc17yq                          178                        0  \n",
       "mpggsq                          158                        0  \n",
       "zlyac8                          152                        1  \n",
       "f06u72                          182                        1  \n",
       "2fv3rc                          126                        1  \n",
       "qyrkxn                          175                        0  \n",
       "237mql                          144                        1  \n",
       "mc750a                          202                        0  \n",
       "30v796                          152                        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>olalu7</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>288</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z9n6mx</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>183</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5k4413</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrg7q5</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uki4do</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>166</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kev1sk</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>213</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>165</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9n6let</th>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jxmtyg</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>254</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51s2ff</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>182</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wi9mcs</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>138</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            slope_of_peak_exercise_st_segment               thal  \\\n",
       "patient_id                                                         \n",
       "olalu7                                      2  reversible_defect   \n",
       "z9n6mx                                      1             normal   \n",
       "5k4413                                      2  reversible_defect   \n",
       "mrg7q5                                      1             normal   \n",
       "uki4do                                      2             normal   \n",
       "kev1sk                                      2             normal   \n",
       "9n6let                                      3             normal   \n",
       "jxmtyg                                      2  reversible_defect   \n",
       "51s2ff                                      1             normal   \n",
       "wi9mcs                                      1             normal   \n",
       "\n",
       "            resting_blood_pressure  chest_pain_type  num_major_vessels  \\\n",
       "patient_id                                                               \n",
       "olalu7                         170                1                  0   \n",
       "z9n6mx                         138                4                  0   \n",
       "5k4413                         120                4                  0   \n",
       "mrg7q5                         102                3                  1   \n",
       "uki4do                         138                4                  1   \n",
       "kev1sk                         122                3                  0   \n",
       "9n6let                         150                1                  0   \n",
       "jxmtyg                         140                3                  3   \n",
       "51s2ff                         138                4                  0   \n",
       "wi9mcs                         138                3                  0   \n",
       "\n",
       "            fasting_blood_sugar_gt_120_mg_per_dl  resting_ekg_results  \\\n",
       "patient_id                                                              \n",
       "olalu7                                         0                    2   \n",
       "z9n6mx                                         0                    0   \n",
       "5k4413                                         0                    2   \n",
       "mrg7q5                                         0                    0   \n",
       "uki4do                                         0                    2   \n",
       "kev1sk                                         0                    0   \n",
       "9n6let                                         0                    0   \n",
       "jxmtyg                                         0                    2   \n",
       "51s2ff                                         0                    2   \n",
       "wi9mcs                                         0                    2   \n",
       "\n",
       "            serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  sex  age  \\\n",
       "patient_id                                                                    \n",
       "olalu7                              288                       0.2    1   59   \n",
       "z9n6mx                              183                       1.4    0   35   \n",
       "5k4413                              177                       2.5    1   43   \n",
       "mrg7q5                              318                       0.0    0   60   \n",
       "uki4do                              166                       3.6    1   61   \n",
       "kev1sk                              213                       0.2    0   43   \n",
       "9n6let                              226                       2.6    0   66   \n",
       "jxmtyg                              254                       2.0    1   69   \n",
       "51s2ff                              271                       0.0    1   59   \n",
       "wi9mcs                              257                       0.0    1   47   \n",
       "\n",
       "            max_heart_rate_achieved  exercise_induced_angina  \n",
       "patient_id                                                    \n",
       "olalu7                          159                        0  \n",
       "z9n6mx                          182                        0  \n",
       "5k4413                          120                        1  \n",
       "mrg7q5                          160                        0  \n",
       "uki4do                          125                        1  \n",
       "kev1sk                          165                        0  \n",
       "9n6let                          114                        0  \n",
       "jxmtyg                          146                        0  \n",
       "51s2ff                          182                        0  \n",
       "wi9mcs                          156                        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_values.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new column called agerange in train_values\n",
    "\n",
    "agelist =[]\n",
    "\n",
    "for age in train_values['age']:\n",
    "    if (21 <= age) & (age<= 40):\n",
    "        agelist.append('21-40')\n",
    "        \n",
    "    if (41 <= age <= 60):\n",
    "        agelist.append('41-60')\n",
    "        \n",
    "    if (61 <= age <= 80):\n",
    "        agelist.append('61-80')\n",
    "        \n",
    "train_values['agerange']=agelist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create new column called agerange in test_values\n",
    "\n",
    "agelist =[]\n",
    "\n",
    "for age in test_values['age']:\n",
    "    if (21 <= age) & (age<= 40):\n",
    "        agelist.append('21-40')\n",
    "        \n",
    "    if (41 <= age <= 60):\n",
    "        agelist.append('41-60')\n",
    "        \n",
    "    if (61 <= age <= 80):\n",
    "        agelist.append('61-80')\n",
    "        \n",
    "test_values['agerange']=agelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>thal</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>agerange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0z64un</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryoo3j</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt1s1x</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>61-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2xjde</th>\n",
       "      <td>1</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>21-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyt4ek</th>\n",
       "      <td>3</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ldukkw</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2gbyh9</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>258</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>daa9kp</th>\n",
       "      <td>2</td>\n",
       "      <td>fixed_defect</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>276</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3nwy2n</th>\n",
       "      <td>3</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>170</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>326</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1r508r</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ldg4b9</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>302</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>61-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xc17yq</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mpggsq</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>140</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>61-80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zlyac8</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>138</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>236</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f06u72</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>21-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2fv3rc</th>\n",
       "      <td>2</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>144</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qyrkxn</th>\n",
       "      <td>2</td>\n",
       "      <td>normal</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>234</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237mql</th>\n",
       "      <td>1</td>\n",
       "      <td>reversible_defect</td>\n",
       "      <td>130</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mc750a</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>21-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30v796</th>\n",
       "      <td>1</td>\n",
       "      <td>normal</td>\n",
       "      <td>136</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>41-60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            slope_of_peak_exercise_st_segment               thal  \\\n",
       "patient_id                                                         \n",
       "0z64un                                      1             normal   \n",
       "ryoo3j                                      2             normal   \n",
       "yt1s1x                                      1             normal   \n",
       "l2xjde                                      1  reversible_defect   \n",
       "oyt4ek                                      3  reversible_defect   \n",
       "ldukkw                                      1             normal   \n",
       "2gbyh9                                      2  reversible_defect   \n",
       "daa9kp                                      2       fixed_defect   \n",
       "3nwy2n                                      3  reversible_defect   \n",
       "1r508r                                      2             normal   \n",
       "ldg4b9                                      2             normal   \n",
       "xc17yq                                      1             normal   \n",
       "mpggsq                                      1             normal   \n",
       "zlyac8                                      2             normal   \n",
       "f06u72                                      2  reversible_defect   \n",
       "2fv3rc                                      2  reversible_defect   \n",
       "qyrkxn                                      2             normal   \n",
       "237mql                                      1  reversible_defect   \n",
       "mc750a                                      1             normal   \n",
       "30v796                                      1             normal   \n",
       "\n",
       "            resting_blood_pressure  chest_pain_type  num_major_vessels  \\\n",
       "patient_id                                                               \n",
       "0z64un                         128                2                  0   \n",
       "ryoo3j                         110                3                  0   \n",
       "yt1s1x                         125                4                  3   \n",
       "l2xjde                         152                4                  0   \n",
       "oyt4ek                         178                1                  0   \n",
       "ldukkw                         130                3                  0   \n",
       "2gbyh9                         150                4                  2   \n",
       "daa9kp                         150                4                  1   \n",
       "3nwy2n                         170                4                  0   \n",
       "1r508r                         120                3                  0   \n",
       "ldg4b9                         120                4                  0   \n",
       "xc17yq                         140                4                  0   \n",
       "mpggsq                         140                3                  0   \n",
       "zlyac8                         138                4                  0   \n",
       "f06u72                         120                1                  0   \n",
       "2fv3rc                         144                4                  0   \n",
       "qyrkxn                         130                2                  0   \n",
       "237mql                         130                4                  1   \n",
       "mc750a                         130                2                  0   \n",
       "30v796                         136                2                  2   \n",
       "\n",
       "            fasting_blood_sugar_gt_120_mg_per_dl  resting_ekg_results  \\\n",
       "patient_id                                                              \n",
       "0z64un                                         0                    2   \n",
       "ryoo3j                                         0                    0   \n",
       "yt1s1x                                         0                    2   \n",
       "l2xjde                                         0                    0   \n",
       "oyt4ek                                         0                    2   \n",
       "ldukkw                                         0                    0   \n",
       "2gbyh9                                         0                    2   \n",
       "daa9kp                                         0                    2   \n",
       "3nwy2n                                         0                    2   \n",
       "1r508r                                         0                    0   \n",
       "ldg4b9                                         0                    2   \n",
       "xc17yq                                         0                    0   \n",
       "mpggsq                                         0                    0   \n",
       "zlyac8                                         0                    2   \n",
       "f06u72                                         0                    0   \n",
       "2fv3rc                                         0                    2   \n",
       "qyrkxn                                         0                    2   \n",
       "237mql                                         0                    0   \n",
       "mc750a                                         0                    2   \n",
       "30v796                                         1                    2   \n",
       "\n",
       "            serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  sex  age  \\\n",
       "patient_id                                                                    \n",
       "0z64un                              308                       0.0    1   45   \n",
       "ryoo3j                              214                       1.6    0   54   \n",
       "yt1s1x                              304                       0.0    1   77   \n",
       "l2xjde                              223                       0.0    1   40   \n",
       "oyt4ek                              270                       4.2    1   59   \n",
       "ldukkw                              180                       0.0    1   42   \n",
       "2gbyh9                              258                       2.6    0   60   \n",
       "daa9kp                              276                       0.6    1   57   \n",
       "3nwy2n                              326                       3.4    1   59   \n",
       "1r508r                              219                       1.6    0   50   \n",
       "ldg4b9                              302                       0.4    1   66   \n",
       "xc17yq                              226                       0.0    1   42   \n",
       "mpggsq                              335                       0.0    1   64   \n",
       "zlyac8                              236                       0.2    0   45   \n",
       "f06u72                              231                       3.8    1   38   \n",
       "2fv3rc                              200                       0.9    1   50   \n",
       "qyrkxn                              234                       0.6    0   45   \n",
       "237mql                              253                       1.4    1   60   \n",
       "mc750a                              204                       0.0    1   29   \n",
       "30v796                              319                       0.0    0   58   \n",
       "\n",
       "            max_heart_rate_achieved  exercise_induced_angina agerange  \n",
       "patient_id                                                             \n",
       "0z64un                          170                        0    41-60  \n",
       "ryoo3j                          158                        0    41-60  \n",
       "yt1s1x                          162                        1    61-80  \n",
       "l2xjde                          181                        0    21-40  \n",
       "oyt4ek                          145                        0    41-60  \n",
       "ldukkw                          150                        0    41-60  \n",
       "2gbyh9                          157                        0    41-60  \n",
       "daa9kp                          112                        1    41-60  \n",
       "3nwy2n                          140                        1    41-60  \n",
       "1r508r                          158                        0    41-60  \n",
       "ldg4b9                          151                        0    61-80  \n",
       "xc17yq                          178                        0    41-60  \n",
       "mpggsq                          158                        0    61-80  \n",
       "zlyac8                          152                        1    41-60  \n",
       "f06u72                          182                        1    21-40  \n",
       "2fv3rc                          126                        1    41-60  \n",
       "qyrkxn                          175                        0    41-60  \n",
       "237mql                          144                        1    41-60  \n",
       "mc750a                          202                        0    21-40  \n",
       "30v796                          152                        0    41-60  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 total features after one-hot encoding.\n",
      "['slope_of_peak_exercise_st_segment', 'resting_blood_pressure', 'chest_pain_type', 'num_major_vessels', 'fasting_blood_sugar_gt_120_mg_per_dl', 'resting_ekg_results', 'serum_cholesterol_mg_per_dl', 'oldpeak_eq_st_depression', 'sex', 'age', 'max_heart_rate_achieved', 'exercise_induced_angina', 'thal_fixed_defect', 'thal_normal', 'thal_reversible_defect', 'agerange_21-40', 'agerange_41-60', 'agerange_61-80']\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the features agerange and thal data using pandas.get_dummies()\n",
    "train_values_final = pd.get_dummies(train_values, columns=['thal','agerange'])\n",
    "\n",
    "# Encode thal and agerange data to numerical values\n",
    "#new_thal = thal.replace({'normal': 0, 'fixed_defect': 1, 'reversible_defect':2})\n",
    "#new_age = agerange.replace({'21 to 40': 0, '41 to 60': 1, '61 to 80':2})\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded = list(train_values_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "# Uncomment the following line to see the encoded feature names\n",
    "print (encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>thal_fixed_defect</th>\n",
       "      <th>thal_normal</th>\n",
       "      <th>thal_reversible_defect</th>\n",
       "      <th>agerange_21-40</th>\n",
       "      <th>agerange_41-60</th>\n",
       "      <th>agerange_61-80</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dtljkq</th>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a2kf1z</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usnkhx</th>\n",
       "      <td>3</td>\n",
       "      <td>160</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>164</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hltlsl</th>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l0c19s</th>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>226</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcexsf</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y3m2bd</th>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>168</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qcjf51</th>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>249</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7zbya5</th>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>233</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23gf0e</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qhz9ye</th>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u25507</th>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j9tw19</th>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5o32oi</th>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o63ri2</th>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5qfar3</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>254</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2s2b1f</th>\n",
       "      <td>2</td>\n",
       "      <td>180</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>327</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nsd00i</th>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0xw93k</th>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nx10r</th>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            slope_of_peak_exercise_st_segment  resting_blood_pressure  \\\n",
       "patient_id                                                              \n",
       "dtljkq                                      1                     130   \n",
       "a2kf1z                                      1                     117   \n",
       "usnkhx                                      3                     160   \n",
       "hltlsl                                      2                     142   \n",
       "l0c19s                                      1                     142   \n",
       "lcexsf                                      1                     152   \n",
       "y3m2bd                                      1                     132   \n",
       "qcjf51                                      1                     120   \n",
       "7zbya5                                      3                     145   \n",
       "23gf0e                                      2                     110   \n",
       "qhz9ye                                      1                     150   \n",
       "u25507                                      1                     112   \n",
       "j9tw19                                      2                     118   \n",
       "5o32oi                                      1                     140   \n",
       "o63ri2                                      1                     140   \n",
       "5qfar3                                      2                     125   \n",
       "2s2b1f                                      2                     180   \n",
       "nsd00i                                      2                     125   \n",
       "0xw93k                                      1                     124   \n",
       "2nx10r                                      1                     160   \n",
       "\n",
       "            chest_pain_type  num_major_vessels  \\\n",
       "patient_id                                       \n",
       "dtljkq                    2                  0   \n",
       "a2kf1z                    4                  2   \n",
       "usnkhx                    4                  3   \n",
       "hltlsl                    4                  3   \n",
       "l0c19s                    4                  0   \n",
       "lcexsf                    3                  1   \n",
       "y3m2bd                    4                  0   \n",
       "qcjf51                    4                  0   \n",
       "7zbya5                    1                  0   \n",
       "23gf0e                    1                  0   \n",
       "qhz9ye                    4                  0   \n",
       "u25507                    4                  1   \n",
       "j9tw19                    4                  0   \n",
       "5o32oi                    4                  0   \n",
       "o63ri2                    4                  0   \n",
       "5qfar3                    4                  2   \n",
       "2s2b1f                    4                  0   \n",
       "nsd00i                    3                  0   \n",
       "0xw93k                    3                  2   \n",
       "2nx10r                    3                  1   \n",
       "\n",
       "            fasting_blood_sugar_gt_120_mg_per_dl  resting_ekg_results  \\\n",
       "patient_id                                                              \n",
       "dtljkq                                         0                    0   \n",
       "a2kf1z                                         1                    0   \n",
       "usnkhx                                         0                    2   \n",
       "hltlsl                                         0                    2   \n",
       "l0c19s                                         0                    2   \n",
       "lcexsf                                         0                    0   \n",
       "y3m2bd                                         0                    0   \n",
       "qcjf51                                         0                    2   \n",
       "7zbya5                                         1                    2   \n",
       "23gf0e                                         0                    2   \n",
       "qhz9ye                                         0                    2   \n",
       "u25507                                         0                    2   \n",
       "j9tw19                                         0                    0   \n",
       "5o32oi                                         0                    0   \n",
       "o63ri2                                         0                    0   \n",
       "5qfar3                                         1                    0   \n",
       "2s2b1f                                         0                    1   \n",
       "nsd00i                                         0                    0   \n",
       "0xw93k                                         1                    0   \n",
       "2nx10r                                         0                    0   \n",
       "\n",
       "            serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  sex  age  \\\n",
       "patient_id                                                                    \n",
       "dtljkq                              266                       0.6    1   49   \n",
       "a2kf1z                              230                       1.4    1   60   \n",
       "usnkhx                              164                       6.2    0   62   \n",
       "hltlsl                              309                       0.0    1   45   \n",
       "l0c19s                              226                       0.0    1   53   \n",
       "lcexsf                              277                       0.0    0   67   \n",
       "y3m2bd                              207                       0.0    1   57   \n",
       "qcjf51                              249                       0.8    1   46   \n",
       "7zbya5                              233                       2.3    1   63   \n",
       "23gf0e                              211                       1.8    1   64   \n",
       "qhz9ye                              270                       0.8    1   58   \n",
       "u25507                              212                       0.1    1   66   \n",
       "j9tw19                              219                       1.2    1   39   \n",
       "5o32oi                              299                       1.6    1   51   \n",
       "o63ri2                              239                       1.2    1   54   \n",
       "5qfar3                              254                       0.2    1   67   \n",
       "2s2b1f                              327                       3.4    0   55   \n",
       "nsd00i                              309                       1.8    1   64   \n",
       "0xw93k                              255                       0.0    1   48   \n",
       "2nx10r                              201                       0.0    0   54   \n",
       "\n",
       "            max_heart_rate_achieved  exercise_induced_angina  \\\n",
       "patient_id                                                     \n",
       "dtljkq                          171                        0   \n",
       "a2kf1z                          160                        1   \n",
       "usnkhx                          145                        0   \n",
       "hltlsl                          147                        1   \n",
       "l0c19s                          111                        1   \n",
       "lcexsf                          172                        0   \n",
       "y3m2bd                          168                        1   \n",
       "qcjf51                          144                        0   \n",
       "7zbya5                          150                        0   \n",
       "23gf0e                          144                        1   \n",
       "qhz9ye                          111                        1   \n",
       "u25507                          132                        1   \n",
       "j9tw19                          140                        0   \n",
       "5o32oi                          173                        1   \n",
       "o63ri2                          160                        0   \n",
       "5qfar3                          163                        0   \n",
       "2s2b1f                          117                        1   \n",
       "nsd00i                          131                        1   \n",
       "0xw93k                          175                        0   \n",
       "2nx10r                          163                        0   \n",
       "\n",
       "            thal_fixed_defect  thal_normal  thal_reversible_defect  \\\n",
       "patient_id                                                           \n",
       "dtljkq                      0            1                       0   \n",
       "a2kf1z                      0            0                       1   \n",
       "usnkhx                      0            0                       1   \n",
       "hltlsl                      0            0                       1   \n",
       "l0c19s                      0            0                       1   \n",
       "lcexsf                      0            1                       0   \n",
       "y3m2bd                      0            0                       1   \n",
       "qcjf51                      0            0                       1   \n",
       "7zbya5                      1            0                       0   \n",
       "23gf0e                      0            1                       0   \n",
       "qhz9ye                      0            0                       1   \n",
       "u25507                      0            1                       0   \n",
       "j9tw19                      0            0                       1   \n",
       "5o32oi                      0            0                       1   \n",
       "o63ri2                      0            1                       0   \n",
       "5qfar3                      0            0                       1   \n",
       "2s2b1f                      0            1                       0   \n",
       "nsd00i                      0            0                       1   \n",
       "0xw93k                      0            1                       0   \n",
       "2nx10r                      0            1                       0   \n",
       "\n",
       "            agerange_21-40  agerange_41-60  agerange_61-80  \n",
       "patient_id                                                  \n",
       "dtljkq                   0               1               0  \n",
       "a2kf1z                   0               1               0  \n",
       "usnkhx                   0               0               1  \n",
       "hltlsl                   0               1               0  \n",
       "l0c19s                   0               1               0  \n",
       "lcexsf                   0               0               1  \n",
       "y3m2bd                   0               1               0  \n",
       "qcjf51                   0               1               0  \n",
       "7zbya5                   0               0               1  \n",
       "23gf0e                   0               0               1  \n",
       "qhz9ye                   0               1               0  \n",
       "u25507                   0               0               1  \n",
       "j9tw19                   1               0               0  \n",
       "5o32oi                   0               1               0  \n",
       "o63ri2                   0               1               0  \n",
       "5qfar3                   0               0               1  \n",
       "2s2b1f                   0               1               0  \n",
       "nsd00i                   0               0               1  \n",
       "0xw93k                   0               1               0  \n",
       "2nx10r                   0               1               0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values_final.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 total features after one-hot encoding.\n",
      "['slope_of_peak_exercise_st_segment', 'resting_blood_pressure', 'chest_pain_type', 'num_major_vessels', 'fasting_blood_sugar_gt_120_mg_per_dl', 'resting_ekg_results', 'serum_cholesterol_mg_per_dl', 'oldpeak_eq_st_depression', 'sex', 'age', 'max_heart_rate_achieved', 'exercise_induced_angina', 'thal_fixed_defect', 'thal_normal', 'thal_reversible_defect', 'agerange_21-40', 'agerange_41-60', 'agerange_61-80']\n"
     ]
    }
   ],
   "source": [
    "# do the same encoding with test_values\n",
    "\n",
    "# One-hot encode the features agerange and thal data using pandas.get_dummies()\n",
    "test_values_final = pd.get_dummies(test_values, columns=['thal','agerange'])\n",
    "\n",
    "# Encode thal and agerange data to numerical values\n",
    "#new_thal = thal.replace({'normal': 0, 'fixed_defect': 1, 'reversible_defect':2})\n",
    "#new_age = agerange.replace({'21 to 40': 0, '41 to 60': 1, '61 to 80':2})\n",
    "\n",
    "# Print the number of features after one-hot encoding\n",
    "encoded_test = list(train_values_final.columns)\n",
    "print(\"{} total features after one-hot encoding.\".format(len(encoded)))\n",
    "\n",
    "# Uncomment the following line to see the encoded feature names\n",
    "print (encoded_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Scaling needs to be done as some features (resting_blood_pressure, max_heart_rate_achieved) have a three digits value and this may have a bigger a influence in the result compared to features that do not have a huge values like them.\n",
    "\n",
    "MinMax Scaler is being used here as this algorithm shrink the range to a value between 0 and 1, so we have a pretty standard values for all the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#feature scaling \n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features_train = scaler.fit_transform(train_values_final)\n",
    "features_test = scaler.fit_transform(test_values_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>thal_fixed_defect</th>\n",
       "      <th>thal_normal</th>\n",
       "      <th>thal_reversible_defect</th>\n",
       "      <th>agerange_21-40</th>\n",
       "      <th>agerange_41-60</th>\n",
       "      <th>agerange_61-80</th>\n",
       "      <th>heart_disease_present</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0z64un</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ryoo3j</th>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yt1s1x</th>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2xjde</th>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oyt4ek</th>\n",
       "      <td>3</td>\n",
       "      <td>178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>270</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>145</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            slope_of_peak_exercise_st_segment  resting_blood_pressure  \\\n",
       "patient_id                                                              \n",
       "0z64un                                      1                     128   \n",
       "ryoo3j                                      2                     110   \n",
       "yt1s1x                                      1                     125   \n",
       "l2xjde                                      1                     152   \n",
       "oyt4ek                                      3                     178   \n",
       "\n",
       "            chest_pain_type  num_major_vessels  \\\n",
       "patient_id                                       \n",
       "0z64un                    2                  0   \n",
       "ryoo3j                    3                  0   \n",
       "yt1s1x                    4                  3   \n",
       "l2xjde                    4                  0   \n",
       "oyt4ek                    1                  0   \n",
       "\n",
       "            fasting_blood_sugar_gt_120_mg_per_dl  resting_ekg_results  \\\n",
       "patient_id                                                              \n",
       "0z64un                                         0                    2   \n",
       "ryoo3j                                         0                    0   \n",
       "yt1s1x                                         0                    2   \n",
       "l2xjde                                         0                    0   \n",
       "oyt4ek                                         0                    2   \n",
       "\n",
       "            serum_cholesterol_mg_per_dl  oldpeak_eq_st_depression  sex  age  \\\n",
       "patient_id                                                                    \n",
       "0z64un                              308                       0.0    1   45   \n",
       "ryoo3j                              214                       1.6    0   54   \n",
       "yt1s1x                              304                       0.0    1   77   \n",
       "l2xjde                              223                       0.0    1   40   \n",
       "oyt4ek                              270                       4.2    1   59   \n",
       "\n",
       "            max_heart_rate_achieved  exercise_induced_angina  \\\n",
       "patient_id                                                     \n",
       "0z64un                          170                        0   \n",
       "ryoo3j                          158                        0   \n",
       "yt1s1x                          162                        1   \n",
       "l2xjde                          181                        0   \n",
       "oyt4ek                          145                        0   \n",
       "\n",
       "            thal_fixed_defect  thal_normal  thal_reversible_defect  \\\n",
       "patient_id                                                           \n",
       "0z64un                      0            1                       0   \n",
       "ryoo3j                      0            1                       0   \n",
       "yt1s1x                      0            1                       0   \n",
       "l2xjde                      0            0                       1   \n",
       "oyt4ek                      0            0                       1   \n",
       "\n",
       "            agerange_21-40  agerange_41-60  agerange_61-80  \\\n",
       "patient_id                                                   \n",
       "0z64un                   0               1               0   \n",
       "ryoo3j                   0               1               0   \n",
       "yt1s1x                   0               0               1   \n",
       "l2xjde                   1               0               0   \n",
       "oyt4ek                   0               1               0   \n",
       "\n",
       "            heart_disease_present  \n",
       "patient_id                         \n",
       "0z64un                          0  \n",
       "ryoo3j                          0  \n",
       "yt1s1x                          1  \n",
       "l2xjde                          1  \n",
       "oyt4ek                          0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#heatmap, cos I'm finding correlation before deciding on the features\n",
    "#first, need to join the train_labels with train_values\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "overall=train_values_final.join(train_labels)\n",
    "overall.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <th>chest_pain_type</th>\n",
       "      <th>num_major_vessels</th>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <th>thal_fixed_defect</th>\n",
       "      <th>thal_normal</th>\n",
       "      <th>thal_reversible_defect</th>\n",
       "      <th>agerange_21-40</th>\n",
       "      <th>agerange_41-60</th>\n",
       "      <th>agerange_61-80</th>\n",
       "      <th>heart_disease_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>slope_of_peak_exercise_st_segment</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.098287</td>\n",
       "      <td>0.121207</td>\n",
       "      <td>0.076832</td>\n",
       "      <td>0.050199</td>\n",
       "      <td>0.172191</td>\n",
       "      <td>-0.032348</td>\n",
       "      <td>0.615948</td>\n",
       "      <td>0.093340</td>\n",
       "      <td>0.169918</td>\n",
       "      <td>-0.418102</td>\n",
       "      <td>0.225459</td>\n",
       "      <td>0.157263</td>\n",
       "      <td>-0.305492</td>\n",
       "      <td>0.243341</td>\n",
       "      <td>-0.077045</td>\n",
       "      <td>-0.052659</td>\n",
       "      <td>0.095793</td>\n",
       "      <td>0.344224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resting_blood_pressure</th>\n",
       "      <td>0.098287</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.029296</td>\n",
       "      <td>0.042388</td>\n",
       "      <td>0.166570</td>\n",
       "      <td>0.078986</td>\n",
       "      <td>0.144881</td>\n",
       "      <td>0.219026</td>\n",
       "      <td>-0.055589</td>\n",
       "      <td>0.284402</td>\n",
       "      <td>-0.017521</td>\n",
       "      <td>0.123397</td>\n",
       "      <td>0.127950</td>\n",
       "      <td>-0.098964</td>\n",
       "      <td>0.046578</td>\n",
       "      <td>-0.068941</td>\n",
       "      <td>-0.144424</td>\n",
       "      <td>0.187908</td>\n",
       "      <td>0.078506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chest_pain_type</th>\n",
       "      <td>0.121207</td>\n",
       "      <td>-0.029296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.249061</td>\n",
       "      <td>-0.088992</td>\n",
       "      <td>0.033379</td>\n",
       "      <td>0.061213</td>\n",
       "      <td>0.080799</td>\n",
       "      <td>0.086057</td>\n",
       "      <td>0.085001</td>\n",
       "      <td>-0.301792</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>-0.007042</td>\n",
       "      <td>-0.300914</td>\n",
       "      <td>0.307524</td>\n",
       "      <td>-0.067190</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>0.412829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_major_vessels</th>\n",
       "      <td>0.076832</td>\n",
       "      <td>0.042388</td>\n",
       "      <td>0.249061</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.169792</td>\n",
       "      <td>0.096656</td>\n",
       "      <td>0.098348</td>\n",
       "      <td>0.214062</td>\n",
       "      <td>0.073107</td>\n",
       "      <td>0.347355</td>\n",
       "      <td>-0.275687</td>\n",
       "      <td>0.153407</td>\n",
       "      <td>-0.015493</td>\n",
       "      <td>-0.185283</td>\n",
       "      <td>0.194026</td>\n",
       "      <td>-0.183282</td>\n",
       "      <td>-0.138740</td>\n",
       "      <td>0.242028</td>\n",
       "      <td>0.421519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fasting_blood_sugar_gt_120_mg_per_dl</th>\n",
       "      <td>0.050199</td>\n",
       "      <td>0.166570</td>\n",
       "      <td>-0.088992</td>\n",
       "      <td>0.169792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.027560</td>\n",
       "      <td>-0.039055</td>\n",
       "      <td>0.066010</td>\n",
       "      <td>0.176101</td>\n",
       "      <td>0.058369</td>\n",
       "      <td>-0.005956</td>\n",
       "      <td>0.125474</td>\n",
       "      <td>-0.023938</td>\n",
       "      <td>-0.028324</td>\n",
       "      <td>-0.111806</td>\n",
       "      <td>-0.021748</td>\n",
       "      <td>0.081597</td>\n",
       "      <td>0.003379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resting_ekg_results</th>\n",
       "      <td>0.172191</td>\n",
       "      <td>0.078986</td>\n",
       "      <td>0.033379</td>\n",
       "      <td>0.096656</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.170839</td>\n",
       "      <td>0.097321</td>\n",
       "      <td>0.045786</td>\n",
       "      <td>0.126856</td>\n",
       "      <td>-0.102766</td>\n",
       "      <td>0.037773</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>0.023521</td>\n",
       "      <td>-0.041946</td>\n",
       "      <td>-0.082669</td>\n",
       "      <td>0.037290</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.145933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serum_cholesterol_mg_per_dl</th>\n",
       "      <td>-0.032348</td>\n",
       "      <td>0.144881</td>\n",
       "      <td>0.061213</td>\n",
       "      <td>0.098348</td>\n",
       "      <td>0.027560</td>\n",
       "      <td>0.170839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021932</td>\n",
       "      <td>-0.152296</td>\n",
       "      <td>0.236211</td>\n",
       "      <td>-0.071038</td>\n",
       "      <td>0.083139</td>\n",
       "      <td>-0.090092</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>0.015760</td>\n",
       "      <td>-0.120142</td>\n",
       "      <td>-0.153982</td>\n",
       "      <td>0.224853</td>\n",
       "      <td>0.079775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oldpeak_eq_st_depression</th>\n",
       "      <td>0.615948</td>\n",
       "      <td>0.219026</td>\n",
       "      <td>0.080799</td>\n",
       "      <td>0.214062</td>\n",
       "      <td>-0.039055</td>\n",
       "      <td>0.097321</td>\n",
       "      <td>-0.021932</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099374</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>-0.341045</td>\n",
       "      <td>0.249167</td>\n",
       "      <td>0.055930</td>\n",
       "      <td>-0.332991</td>\n",
       "      <td>0.313616</td>\n",
       "      <td>-0.008504</td>\n",
       "      <td>-0.061858</td>\n",
       "      <td>0.069433</td>\n",
       "      <td>0.382930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.093340</td>\n",
       "      <td>-0.055589</td>\n",
       "      <td>0.086057</td>\n",
       "      <td>0.073107</td>\n",
       "      <td>0.066010</td>\n",
       "      <td>0.045786</td>\n",
       "      <td>-0.152296</td>\n",
       "      <td>0.099374</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.148997</td>\n",
       "      <td>-0.053960</td>\n",
       "      <td>0.251096</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>-0.421950</td>\n",
       "      <td>0.366381</td>\n",
       "      <td>0.071252</td>\n",
       "      <td>0.177716</td>\n",
       "      <td>-0.224086</td>\n",
       "      <td>0.335421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.169918</td>\n",
       "      <td>0.284402</td>\n",
       "      <td>0.085001</td>\n",
       "      <td>0.347355</td>\n",
       "      <td>0.176101</td>\n",
       "      <td>0.126856</td>\n",
       "      <td>0.236211</td>\n",
       "      <td>0.189700</td>\n",
       "      <td>-0.148997</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.394630</td>\n",
       "      <td>0.081811</td>\n",
       "      <td>0.070984</td>\n",
       "      <td>-0.049719</td>\n",
       "      <td>0.020593</td>\n",
       "      <td>-0.490640</td>\n",
       "      <td>-0.471392</td>\n",
       "      <td>0.752912</td>\n",
       "      <td>0.138255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_heart_rate_achieved</th>\n",
       "      <td>-0.418102</td>\n",
       "      <td>-0.017521</td>\n",
       "      <td>-0.301792</td>\n",
       "      <td>-0.275687</td>\n",
       "      <td>0.058369</td>\n",
       "      <td>-0.102766</td>\n",
       "      <td>-0.071038</td>\n",
       "      <td>-0.341045</td>\n",
       "      <td>-0.053960</td>\n",
       "      <td>-0.394630</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.365065</td>\n",
       "      <td>-0.132164</td>\n",
       "      <td>0.271064</td>\n",
       "      <td>-0.219006</td>\n",
       "      <td>0.192573</td>\n",
       "      <td>0.185642</td>\n",
       "      <td>-0.296168</td>\n",
       "      <td>-0.375352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exercise_induced_angina</th>\n",
       "      <td>0.225459</td>\n",
       "      <td>0.123397</td>\n",
       "      <td>0.346266</td>\n",
       "      <td>0.153407</td>\n",
       "      <td>-0.005956</td>\n",
       "      <td>0.037773</td>\n",
       "      <td>0.083139</td>\n",
       "      <td>0.249167</td>\n",
       "      <td>0.251096</td>\n",
       "      <td>0.081811</td>\n",
       "      <td>-0.365065</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>-0.384491</td>\n",
       "      <td>0.402114</td>\n",
       "      <td>0.075619</td>\n",
       "      <td>-0.043246</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.448647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal_fixed_defect</th>\n",
       "      <td>0.157263</td>\n",
       "      <td>0.127950</td>\n",
       "      <td>-0.007042</td>\n",
       "      <td>-0.015493</td>\n",
       "      <td>0.125474</td>\n",
       "      <td>0.043308</td>\n",
       "      <td>-0.090092</td>\n",
       "      <td>0.055930</td>\n",
       "      <td>0.144932</td>\n",
       "      <td>0.070984</td>\n",
       "      <td>-0.132164</td>\n",
       "      <td>-0.030908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.235769</td>\n",
       "      <td>-0.180195</td>\n",
       "      <td>-0.055022</td>\n",
       "      <td>-0.008761</td>\n",
       "      <td>0.038116</td>\n",
       "      <td>0.024112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal_normal</th>\n",
       "      <td>-0.305492</td>\n",
       "      <td>-0.098964</td>\n",
       "      <td>-0.300914</td>\n",
       "      <td>-0.185283</td>\n",
       "      <td>-0.023938</td>\n",
       "      <td>0.023521</td>\n",
       "      <td>0.021710</td>\n",
       "      <td>-0.332991</td>\n",
       "      <td>-0.421950</td>\n",
       "      <td>-0.049719</td>\n",
       "      <td>0.271064</td>\n",
       "      <td>-0.384491</td>\n",
       "      <td>-0.235769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.913417</td>\n",
       "      <td>-0.092624</td>\n",
       "      <td>-0.050233</td>\n",
       "      <td>0.101433</td>\n",
       "      <td>-0.528812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thal_reversible_defect</th>\n",
       "      <td>0.243341</td>\n",
       "      <td>0.046578</td>\n",
       "      <td>0.307524</td>\n",
       "      <td>0.194026</td>\n",
       "      <td>-0.028324</td>\n",
       "      <td>-0.041946</td>\n",
       "      <td>0.015760</td>\n",
       "      <td>0.313616</td>\n",
       "      <td>0.366381</td>\n",
       "      <td>0.020593</td>\n",
       "      <td>-0.219006</td>\n",
       "      <td>0.402114</td>\n",
       "      <td>-0.180195</td>\n",
       "      <td>-0.913417</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.116796</td>\n",
       "      <td>0.054514</td>\n",
       "      <td>-0.118631</td>\n",
       "      <td>0.525145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agerange_21-40</th>\n",
       "      <td>-0.077045</td>\n",
       "      <td>-0.068941</td>\n",
       "      <td>-0.067190</td>\n",
       "      <td>-0.183282</td>\n",
       "      <td>-0.111806</td>\n",
       "      <td>-0.082669</td>\n",
       "      <td>-0.120142</td>\n",
       "      <td>-0.008504</td>\n",
       "      <td>0.071252</td>\n",
       "      <td>-0.490640</td>\n",
       "      <td>0.192573</td>\n",
       "      <td>0.075619</td>\n",
       "      <td>-0.055022</td>\n",
       "      <td>-0.092624</td>\n",
       "      <td>0.116796</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.343473</td>\n",
       "      <td>-0.164812</td>\n",
       "      <td>0.051862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agerange_41-60</th>\n",
       "      <td>-0.052659</td>\n",
       "      <td>-0.144424</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>-0.138740</td>\n",
       "      <td>-0.021748</td>\n",
       "      <td>0.037290</td>\n",
       "      <td>-0.153982</td>\n",
       "      <td>-0.061858</td>\n",
       "      <td>0.177716</td>\n",
       "      <td>-0.471392</td>\n",
       "      <td>0.185642</td>\n",
       "      <td>-0.043246</td>\n",
       "      <td>-0.008761</td>\n",
       "      <td>-0.050233</td>\n",
       "      <td>0.054514</td>\n",
       "      <td>-0.343473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.869711</td>\n",
       "      <td>-0.059689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agerange_61-80</th>\n",
       "      <td>0.095793</td>\n",
       "      <td>0.187908</td>\n",
       "      <td>0.022865</td>\n",
       "      <td>0.242028</td>\n",
       "      <td>0.081597</td>\n",
       "      <td>0.004283</td>\n",
       "      <td>0.224853</td>\n",
       "      <td>0.069433</td>\n",
       "      <td>-0.224086</td>\n",
       "      <td>0.752912</td>\n",
       "      <td>-0.296168</td>\n",
       "      <td>0.005677</td>\n",
       "      <td>0.038116</td>\n",
       "      <td>0.101433</td>\n",
       "      <td>-0.118631</td>\n",
       "      <td>-0.164812</td>\n",
       "      <td>-0.869711</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_disease_present</th>\n",
       "      <td>0.344224</td>\n",
       "      <td>0.078506</td>\n",
       "      <td>0.412829</td>\n",
       "      <td>0.421519</td>\n",
       "      <td>0.003379</td>\n",
       "      <td>0.145933</td>\n",
       "      <td>0.079775</td>\n",
       "      <td>0.382930</td>\n",
       "      <td>0.335421</td>\n",
       "      <td>0.138255</td>\n",
       "      <td>-0.375352</td>\n",
       "      <td>0.448647</td>\n",
       "      <td>0.024112</td>\n",
       "      <td>-0.528812</td>\n",
       "      <td>0.525145</td>\n",
       "      <td>0.051862</td>\n",
       "      <td>-0.059689</td>\n",
       "      <td>0.035431</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      slope_of_peak_exercise_st_segment  \\\n",
       "slope_of_peak_exercise_st_segment                              1.000000   \n",
       "resting_blood_pressure                                         0.098287   \n",
       "chest_pain_type                                                0.121207   \n",
       "num_major_vessels                                              0.076832   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl                           0.050199   \n",
       "resting_ekg_results                                            0.172191   \n",
       "serum_cholesterol_mg_per_dl                                   -0.032348   \n",
       "oldpeak_eq_st_depression                                       0.615948   \n",
       "sex                                                            0.093340   \n",
       "age                                                            0.169918   \n",
       "max_heart_rate_achieved                                       -0.418102   \n",
       "exercise_induced_angina                                        0.225459   \n",
       "thal_fixed_defect                                              0.157263   \n",
       "thal_normal                                                   -0.305492   \n",
       "thal_reversible_defect                                         0.243341   \n",
       "agerange_21-40                                                -0.077045   \n",
       "agerange_41-60                                                -0.052659   \n",
       "agerange_61-80                                                 0.095793   \n",
       "heart_disease_present                                          0.344224   \n",
       "\n",
       "                                      resting_blood_pressure  chest_pain_type  \\\n",
       "slope_of_peak_exercise_st_segment                   0.098287         0.121207   \n",
       "resting_blood_pressure                              1.000000        -0.029296   \n",
       "chest_pain_type                                    -0.029296         1.000000   \n",
       "num_major_vessels                                   0.042388         0.249061   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl                0.166570        -0.088992   \n",
       "resting_ekg_results                                 0.078986         0.033379   \n",
       "serum_cholesterol_mg_per_dl                         0.144881         0.061213   \n",
       "oldpeak_eq_st_depression                            0.219026         0.080799   \n",
       "sex                                                -0.055589         0.086057   \n",
       "age                                                 0.284402         0.085001   \n",
       "max_heart_rate_achieved                            -0.017521        -0.301792   \n",
       "exercise_induced_angina                             0.123397         0.346266   \n",
       "thal_fixed_defect                                   0.127950        -0.007042   \n",
       "thal_normal                                        -0.098964        -0.300914   \n",
       "thal_reversible_defect                              0.046578         0.307524   \n",
       "agerange_21-40                                     -0.068941        -0.067190   \n",
       "agerange_41-60                                     -0.144424         0.011850   \n",
       "agerange_61-80                                      0.187908         0.022865   \n",
       "heart_disease_present                               0.078506         0.412829   \n",
       "\n",
       "                                      num_major_vessels  \\\n",
       "slope_of_peak_exercise_st_segment              0.076832   \n",
       "resting_blood_pressure                         0.042388   \n",
       "chest_pain_type                                0.249061   \n",
       "num_major_vessels                              1.000000   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl           0.169792   \n",
       "resting_ekg_results                            0.096656   \n",
       "serum_cholesterol_mg_per_dl                    0.098348   \n",
       "oldpeak_eq_st_depression                       0.214062   \n",
       "sex                                            0.073107   \n",
       "age                                            0.347355   \n",
       "max_heart_rate_achieved                       -0.275687   \n",
       "exercise_induced_angina                        0.153407   \n",
       "thal_fixed_defect                             -0.015493   \n",
       "thal_normal                                   -0.185283   \n",
       "thal_reversible_defect                         0.194026   \n",
       "agerange_21-40                                -0.183282   \n",
       "agerange_41-60                                -0.138740   \n",
       "agerange_61-80                                 0.242028   \n",
       "heart_disease_present                          0.421519   \n",
       "\n",
       "                                      fasting_blood_sugar_gt_120_mg_per_dl  \\\n",
       "slope_of_peak_exercise_st_segment                                 0.050199   \n",
       "resting_blood_pressure                                            0.166570   \n",
       "chest_pain_type                                                  -0.088992   \n",
       "num_major_vessels                                                 0.169792   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl                              1.000000   \n",
       "resting_ekg_results                                               0.053864   \n",
       "serum_cholesterol_mg_per_dl                                       0.027560   \n",
       "oldpeak_eq_st_depression                                         -0.039055   \n",
       "sex                                                               0.066010   \n",
       "age                                                               0.176101   \n",
       "max_heart_rate_achieved                                           0.058369   \n",
       "exercise_induced_angina                                          -0.005956   \n",
       "thal_fixed_defect                                                 0.125474   \n",
       "thal_normal                                                      -0.023938   \n",
       "thal_reversible_defect                                           -0.028324   \n",
       "agerange_21-40                                                   -0.111806   \n",
       "agerange_41-60                                                   -0.021748   \n",
       "agerange_61-80                                                    0.081597   \n",
       "heart_disease_present                                             0.003379   \n",
       "\n",
       "                                      resting_ekg_results  \\\n",
       "slope_of_peak_exercise_st_segment                0.172191   \n",
       "resting_blood_pressure                           0.078986   \n",
       "chest_pain_type                                  0.033379   \n",
       "num_major_vessels                                0.096656   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl             0.053864   \n",
       "resting_ekg_results                              1.000000   \n",
       "serum_cholesterol_mg_per_dl                      0.170839   \n",
       "oldpeak_eq_st_depression                         0.097321   \n",
       "sex                                              0.045786   \n",
       "age                                              0.126856   \n",
       "max_heart_rate_achieved                         -0.102766   \n",
       "exercise_induced_angina                          0.037773   \n",
       "thal_fixed_defect                                0.043308   \n",
       "thal_normal                                      0.023521   \n",
       "thal_reversible_defect                          -0.041946   \n",
       "agerange_21-40                                  -0.082669   \n",
       "agerange_41-60                                   0.037290   \n",
       "agerange_61-80                                   0.004283   \n",
       "heart_disease_present                            0.145933   \n",
       "\n",
       "                                      serum_cholesterol_mg_per_dl  \\\n",
       "slope_of_peak_exercise_st_segment                       -0.032348   \n",
       "resting_blood_pressure                                   0.144881   \n",
       "chest_pain_type                                          0.061213   \n",
       "num_major_vessels                                        0.098348   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl                     0.027560   \n",
       "resting_ekg_results                                      0.170839   \n",
       "serum_cholesterol_mg_per_dl                              1.000000   \n",
       "oldpeak_eq_st_depression                                -0.021932   \n",
       "sex                                                     -0.152296   \n",
       "age                                                      0.236211   \n",
       "max_heart_rate_achieved                                 -0.071038   \n",
       "exercise_induced_angina                                  0.083139   \n",
       "thal_fixed_defect                                       -0.090092   \n",
       "thal_normal                                              0.021710   \n",
       "thal_reversible_defect                                   0.015760   \n",
       "agerange_21-40                                          -0.120142   \n",
       "agerange_41-60                                          -0.153982   \n",
       "agerange_61-80                                           0.224853   \n",
       "heart_disease_present                                    0.079775   \n",
       "\n",
       "                                      oldpeak_eq_st_depression       sex  \\\n",
       "slope_of_peak_exercise_st_segment                     0.615948  0.093340   \n",
       "resting_blood_pressure                                0.219026 -0.055589   \n",
       "chest_pain_type                                       0.080799  0.086057   \n",
       "num_major_vessels                                     0.214062  0.073107   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl                 -0.039055  0.066010   \n",
       "resting_ekg_results                                   0.097321  0.045786   \n",
       "serum_cholesterol_mg_per_dl                          -0.021932 -0.152296   \n",
       "oldpeak_eq_st_depression                              1.000000  0.099374   \n",
       "sex                                                   0.099374  1.000000   \n",
       "age                                                   0.189700 -0.148997   \n",
       "max_heart_rate_achieved                              -0.341045 -0.053960   \n",
       "exercise_induced_angina                               0.249167  0.251096   \n",
       "thal_fixed_defect                                     0.055930  0.144932   \n",
       "thal_normal                                          -0.332991 -0.421950   \n",
       "thal_reversible_defect                                0.313616  0.366381   \n",
       "agerange_21-40                                       -0.008504  0.071252   \n",
       "agerange_41-60                                       -0.061858  0.177716   \n",
       "agerange_61-80                                        0.069433 -0.224086   \n",
       "heart_disease_present                                 0.382930  0.335421   \n",
       "\n",
       "                                           age  max_heart_rate_achieved  \\\n",
       "slope_of_peak_exercise_st_segment     0.169918                -0.418102   \n",
       "resting_blood_pressure                0.284402                -0.017521   \n",
       "chest_pain_type                       0.085001                -0.301792   \n",
       "num_major_vessels                     0.347355                -0.275687   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl  0.176101                 0.058369   \n",
       "resting_ekg_results                   0.126856                -0.102766   \n",
       "serum_cholesterol_mg_per_dl           0.236211                -0.071038   \n",
       "oldpeak_eq_st_depression              0.189700                -0.341045   \n",
       "sex                                  -0.148997                -0.053960   \n",
       "age                                   1.000000                -0.394630   \n",
       "max_heart_rate_achieved              -0.394630                 1.000000   \n",
       "exercise_induced_angina               0.081811                -0.365065   \n",
       "thal_fixed_defect                     0.070984                -0.132164   \n",
       "thal_normal                          -0.049719                 0.271064   \n",
       "thal_reversible_defect                0.020593                -0.219006   \n",
       "agerange_21-40                       -0.490640                 0.192573   \n",
       "agerange_41-60                       -0.471392                 0.185642   \n",
       "agerange_61-80                        0.752912                -0.296168   \n",
       "heart_disease_present                 0.138255                -0.375352   \n",
       "\n",
       "                                      exercise_induced_angina  \\\n",
       "slope_of_peak_exercise_st_segment                    0.225459   \n",
       "resting_blood_pressure                               0.123397   \n",
       "chest_pain_type                                      0.346266   \n",
       "num_major_vessels                                    0.153407   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl                -0.005956   \n",
       "resting_ekg_results                                  0.037773   \n",
       "serum_cholesterol_mg_per_dl                          0.083139   \n",
       "oldpeak_eq_st_depression                             0.249167   \n",
       "sex                                                  0.251096   \n",
       "age                                                  0.081811   \n",
       "max_heart_rate_achieved                             -0.365065   \n",
       "exercise_induced_angina                              1.000000   \n",
       "thal_fixed_defect                                   -0.030908   \n",
       "thal_normal                                         -0.384491   \n",
       "thal_reversible_defect                               0.402114   \n",
       "agerange_21-40                                       0.075619   \n",
       "agerange_41-60                                      -0.043246   \n",
       "agerange_61-80                                       0.005677   \n",
       "heart_disease_present                                0.448647   \n",
       "\n",
       "                                      thal_fixed_defect  thal_normal  \\\n",
       "slope_of_peak_exercise_st_segment              0.157263    -0.305492   \n",
       "resting_blood_pressure                         0.127950    -0.098964   \n",
       "chest_pain_type                               -0.007042    -0.300914   \n",
       "num_major_vessels                             -0.015493    -0.185283   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl           0.125474    -0.023938   \n",
       "resting_ekg_results                            0.043308     0.023521   \n",
       "serum_cholesterol_mg_per_dl                   -0.090092     0.021710   \n",
       "oldpeak_eq_st_depression                       0.055930    -0.332991   \n",
       "sex                                            0.144932    -0.421950   \n",
       "age                                            0.070984    -0.049719   \n",
       "max_heart_rate_achieved                       -0.132164     0.271064   \n",
       "exercise_induced_angina                       -0.030908    -0.384491   \n",
       "thal_fixed_defect                              1.000000    -0.235769   \n",
       "thal_normal                                   -0.235769     1.000000   \n",
       "thal_reversible_defect                        -0.180195    -0.913417   \n",
       "agerange_21-40                                -0.055022    -0.092624   \n",
       "agerange_41-60                                -0.008761    -0.050233   \n",
       "agerange_61-80                                 0.038116     0.101433   \n",
       "heart_disease_present                          0.024112    -0.528812   \n",
       "\n",
       "                                      thal_reversible_defect  agerange_21-40  \\\n",
       "slope_of_peak_exercise_st_segment                   0.243341       -0.077045   \n",
       "resting_blood_pressure                              0.046578       -0.068941   \n",
       "chest_pain_type                                     0.307524       -0.067190   \n",
       "num_major_vessels                                   0.194026       -0.183282   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl               -0.028324       -0.111806   \n",
       "resting_ekg_results                                -0.041946       -0.082669   \n",
       "serum_cholesterol_mg_per_dl                         0.015760       -0.120142   \n",
       "oldpeak_eq_st_depression                            0.313616       -0.008504   \n",
       "sex                                                 0.366381        0.071252   \n",
       "age                                                 0.020593       -0.490640   \n",
       "max_heart_rate_achieved                            -0.219006        0.192573   \n",
       "exercise_induced_angina                             0.402114        0.075619   \n",
       "thal_fixed_defect                                  -0.180195       -0.055022   \n",
       "thal_normal                                        -0.913417       -0.092624   \n",
       "thal_reversible_defect                              1.000000        0.116796   \n",
       "agerange_21-40                                      0.116796        1.000000   \n",
       "agerange_41-60                                      0.054514       -0.343473   \n",
       "agerange_61-80                                     -0.118631       -0.164812   \n",
       "heart_disease_present                               0.525145        0.051862   \n",
       "\n",
       "                                      agerange_41-60  agerange_61-80  \\\n",
       "slope_of_peak_exercise_st_segment          -0.052659        0.095793   \n",
       "resting_blood_pressure                     -0.144424        0.187908   \n",
       "chest_pain_type                             0.011850        0.022865   \n",
       "num_major_vessels                          -0.138740        0.242028   \n",
       "fasting_blood_sugar_gt_120_mg_per_dl       -0.021748        0.081597   \n",
       "resting_ekg_results                         0.037290        0.004283   \n",
       "serum_cholesterol_mg_per_dl                -0.153982        0.224853   \n",
       "oldpeak_eq_st_depression                   -0.061858        0.069433   \n",
       "sex                                         0.177716       -0.224086   \n",
       "age                                        -0.471392        0.752912   \n",
       "max_heart_rate_achieved                     0.185642       -0.296168   \n",
       "exercise_induced_angina                    -0.043246        0.005677   \n",
       "thal_fixed_defect                          -0.008761        0.038116   \n",
       "thal_normal                                -0.050233        0.101433   \n",
       "thal_reversible_defect                      0.054514       -0.118631   \n",
       "agerange_21-40                             -0.343473       -0.164812   \n",
       "agerange_41-60                              1.000000       -0.869711   \n",
       "agerange_61-80                             -0.869711        1.000000   \n",
       "heart_disease_present                      -0.059689        0.035431   \n",
       "\n",
       "                                      heart_disease_present  \n",
       "slope_of_peak_exercise_st_segment                  0.344224  \n",
       "resting_blood_pressure                             0.078506  \n",
       "chest_pain_type                                    0.412829  \n",
       "num_major_vessels                                  0.421519  \n",
       "fasting_blood_sugar_gt_120_mg_per_dl               0.003379  \n",
       "resting_ekg_results                                0.145933  \n",
       "serum_cholesterol_mg_per_dl                        0.079775  \n",
       "oldpeak_eq_st_depression                           0.382930  \n",
       "sex                                                0.335421  \n",
       "age                                                0.138255  \n",
       "max_heart_rate_achieved                           -0.375352  \n",
       "exercise_induced_angina                            0.448647  \n",
       "thal_fixed_defect                                  0.024112  \n",
       "thal_normal                                       -0.528812  \n",
       "thal_reversible_defect                             0.525145  \n",
       "agerange_21-40                                     0.051862  \n",
       "agerange_41-60                                    -0.059689  \n",
       "agerange_61-80                                     0.035431  \n",
       "heart_disease_present                              1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr=overall.corr()\n",
    "\n",
    "display(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xc2e2748>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABAoAAAL8CAYAAABpv1cSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nU3EgkLsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc2f71d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,10))\n",
    "sns.heatmap(corr, \n",
    "            xticklabels=corr.columns.values,\n",
    "            yticklabels=corr.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the heatmap above, we can see some featurs have a strong correlation with each other(eg; thal_normal and thal_reversible_defect has a strong negative correlation, while slope_of_peak_exercise_st_segment and oldpeak_eq_st_depression has a pretty strong positive correlation). Some moderate correlations also present in this heatmap (eg; thal_reversible_defect and exercise_induced_angina that has a moderate positive correlation). \n",
    "\n",
    "The heatmap tells us that the features are not independent of one another, as some featurs are strongly correlated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation slope_of_peak_exercise_st_segment : 0.344223986923\n",
      "Correlation resting_blood_pressure : 0.0785057354407\n",
      "Correlation chest_pain_type : 0.412828625366\n",
      "Correlation num_major_vessels : 0.421518626048\n",
      "Correlation fasting_blood_sugar_gt_120_mg_per_dl : 0.0033790726529\n",
      "Correlation resting_ekg_results : 0.145933394351\n",
      "Correlation serum_cholesterol_mg_per_dl : 0.0797748513149\n",
      "Correlation oldpeak_eq_st_depression : 0.382930227959\n",
      "Correlation sex : 0.335420930266\n",
      "Correlation age : 0.138254706651\n",
      "Correlation max_heart_rate_achieved : -0.375351869368\n",
      "Correlation exercise_induced_angina : 0.448646516812\n",
      "Correlation thal_fixed_defect : 0.0241121411085\n",
      "Correlation thal_normal : -0.528811509654\n",
      "Correlation thal_reversible_defect : 0.525145374593\n",
      "Correlation agerange_21-40 : 0.0518615278818\n",
      "Correlation agerange_41-60 : -0.0596889386449\n",
      "Correlation agerange_61-80 : 0.0354314200906\n",
      "Correlation heart_disease_present : 1.0\n"
     ]
    }
   ],
   "source": [
    "#get correlation to heart_disease_present\n",
    "\n",
    "def get_corr(feature):\n",
    "\n",
    "    return overall[feature].corr(overall['heart_disease_present'])\n",
    "\n",
    "for feature in overall:\n",
    "    print ('Correlation', feature,':', get_corr(feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the Top 5 features with the highest Pearson's correlation score:-\n",
    "\n",
    "* thal_normal : -0.528811509654\n",
    "* thal_reversible_defect : 0.525145374593\n",
    "* exercise_induced_angina : 0.448646516812\n",
    "* num_major_vessels : 0.421518626048\n",
    "* chest_pain_type : 0.412828625366\n",
    "\n",
    "There is a correlation between these five features with heart_disease_present feature, however, looking at the scores, the correlation isn't that strong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 144 samples.\n",
      "Testing set has 36 samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features_train' and 'train_labels' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_train, \n",
    "                                                    train_labels, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the dataset has been split into training and testing, I still want to further split the training set into training and testing set. This is because I do not want the algorithm to 'see' the data first. This will reduce the possibility of overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifiers\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# import metrics\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss score for Gauss 1.41284755558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def gauss_(features_train,labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf_Gauss = GaussianNB()\n",
    "    clf_Gauss.fit(features_train, labels_train)\n",
    "    pred=clf_Gauss.predict_proba(features_test)\n",
    "\n",
    "    #print 'precision score Gaussian', precision_score(labels_test, pred)\n",
    "    #print 'recall score Gaussian', recall_score(labels_test, pred)\n",
    "    print ('log_loss score for Gauss', log_loss(labels_test, pred))\n",
    "    \n",
    "    return clf_Gauss\n",
    "\n",
    "gauss_(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss score for Decision Tree with no parameter tuning: 12.4723359204\n"
     ]
    }
   ],
   "source": [
    "def dt_(features_train,labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf_dt = DecisionTreeClassifier()\n",
    "    clf_dt.fit(features_train, labels_train)\n",
    "    pred=clf_dt.predict_proba(features_test)\n",
    "\n",
    "    print ('log_loss score for Decision Tree with no parameter tuning:', log_loss(labels_test, pred))\n",
    "\n",
    "\n",
    "dt_(X_train, y_train, X_test, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss score for KNN with no parameter tuning: 1.26710858796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "def knn_(features_train,labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf_knn = KNeighborsClassifier() \n",
    "    clf_knn.fit(features_train, labels_train)\n",
    "    pred=clf_knn.predict_proba(features_test)\n",
    "\n",
    "    print ('log_loss score for KNN with no parameter tuning:', log_loss(labels_test, pred))\n",
    "\n",
    "\n",
    "knn_(X_train, y_train, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss score for Logistic Regression with no parameter tuning: 0.393955341314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "def lr_(features_train,labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf_lr = LogisticRegression() \n",
    "    clf_lr.fit(features_train, labels_train)\n",
    "    pred=clf_lr.predict_proba(features_test)\n",
    "\n",
    "    print ('log_loss score for Logistic Regression with no parameter tuning:', log_loss(labels_test, pred))\n",
    "\n",
    "lr_(X_train, y_train, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the best score comes from Logistic Regression at 0.394\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss score for Adaboost with no parameter tuning: 0.64499836175\n"
     ]
    }
   ],
   "source": [
    "def adb_(features_train,labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf_adb = AdaBoostClassifier()\n",
    "    clf_adb.fit(features_train, labels_train)\n",
    "    pred=clf_adb.predict_proba(features_test)\n",
    "\n",
    "    print ('log_loss score for Adaboost with no parameter tuning:', log_loss(labels_test, pred))\n",
    "\n",
    "\n",
    "adb_(X_train, y_train, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss score for Voting Classifier with no parameter tuning: 0.420223293515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = KNeighborsClassifier() \n",
    "clf3 = GaussianNB()\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "         ('lr', clf1), ('knn', clf2), ('gnb', clf3)], voting='soft')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "\n",
    "pred=eclf1.predict_proba(X_test)\n",
    "\n",
    "print ('log_loss score for Voting Classifier with no parameter tuning:', log_loss(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base results for all the classifiers\n",
    "\n",
    "Log-loss base score for all the classifiers as below:-\n",
    "* Gaussian Naive Bayes : 1.41\n",
    "* Decision Tree: 10.55\n",
    "* K-Nearest Neighbors: 1.27\n",
    "* Logistic Regression: 0.39\n",
    "* Adaboost:  0.645\n",
    "* Stacking: 0.44\n",
    "\n",
    "Amongst them, Logistic Regression and Stacking algorith performs better than the benchmark of 0.5381. The benchmark is also using Logistic Regression, so it is surprising how this model could perform better than the benckmark although they are using the same algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parameters tuning with GridSearch CV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def get_bestclf(clf, parameters):\n",
    "    grid_obj = GridSearchCV(clf, scoring= make_scorer(log_loss), param_grid=parameters)\n",
    "    grid_fit = grid_obj.fit(X_train, y_train)\n",
    "    best_clf = grid_fit.best_estimator_\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Decision Tree after Parameters tuning: 6.88407626532\n"
     ]
    }
   ],
   "source": [
    "#GaussianNB() no need to set parameters\n",
    "# Below is the Decision Tree after parameters tuning\n",
    "\n",
    "best_DT= get_bestclf(DecisionTreeClassifier(), parameters = {'criterion':['gini', 'entropy'], 'max_depth': [None, 2, 3, 4, 5]})\n",
    "best_predictions = best_DT.predict_proba(X_test)\n",
    "print ('Score for Decision Tree after Parameters tuning:', log_loss(y_test, best_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for KNN after Parameters tuning: 2.18114830095\n"
     ]
    }
   ],
   "source": [
    "# Parameters tuning for KNN\n",
    "\n",
    "best_KNN= get_bestclf(KNeighborsClassifier(), parameters = {'n_neighbors':[2,4,5,6,8], 'weights': ['uniform', 'distance'],\n",
    "                                                            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']})\n",
    "best_predictions = best_KNN.predict_proba(X_test)\n",
    "print ('Score for KNN after Parameters tuning:', log_loss(y_test, best_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Logistic Regression after Parameters tuning: 0.409102334537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Parameters tuning for Logistic Regression\n",
    "\n",
    "best_lr= get_bestclf(LogisticRegression(), parameters = {'C':[0.1, 0.5, 1.0, 1.5, 2.0], 'tol': [0.1, 0.01, 1.0, 0.5],\n",
    "                                                            'solver': ['liblinear']})\n",
    "best_predictions = best_lr.predict_proba(X_test)\n",
    "print ('Score for Logistic Regression after Parameters tuning:', log_loss(y_test, best_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for AdaBoost after Parameters tuning: 0.692730947712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Parameters tuning for Adaboost\n",
    "\n",
    "best_adb= get_bestclf(AdaBoostClassifier(), parameters = {'n_estimators': [10, 50, 100, 250, 500, 1000], \n",
    "                                                          'learning_rate': [0.001, 0.1,1, 2.0],\n",
    "                                                          'algorithm': ['SAMME', 'SAMME.R']})\n",
    "best_predictions = best_adb.predict_proba(X_test)\n",
    "print ('Score for AdaBoost after Parameters tuning:', log_loss(y_test, best_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for Best Stacking after Parameters tuning: 0.477204902594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# stacking parameters\n",
    "\n",
    "#eclf_best = VotingClassifier(estimators=[\n",
    "#         ('best_lr', best_lr), ('best_adb', best_adb), ('best_KNN', best_KNN), ('best_DT', best_DT)], voting='soft')\n",
    "\n",
    "eclf_best = VotingClassifier(estimators=[\n",
    "         ('best_lr', best_lr), ('best_adb', best_adb), ('gnb', clf3)], voting='soft')\n",
    "\n",
    "best_stack = eclf_best.fit(X_train, y_train)\n",
    "\n",
    "best_predictions=best_stack.predict_proba(X_test)\n",
    "print ('Score for Best Stacking after Parameters tuning:', log_loss(y_test, best_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log-loss score after parameters tuning (with the exception of Gaussian Naive Bayes) for all the classifiers as below:-\n",
    "* Gaussian Naive Bayes : 1.41\n",
    "* Decision Tree: 9.59\n",
    "* K-Nearest Neighbors: 2.18\n",
    "* Logistic Regression: 0.41\n",
    "* Adaboost:  0.693\n",
    "* Stacking: 0.436\n",
    "\n",
    "Amongst the algorithm above, Decision Tree and Stacking method has improved slightly using GridSearchCV, while the rest actually performed worse than when parameters were not tuned in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02  0.04  0.04  0.04  0.02  0.02  0.14  0.14  0.06  0.22  0.18  0.04\n",
      "  0.    0.02  0.02  0.    0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "\n",
    "# TODO: Train the supervised model on the training set using .fit(X_train, y_train)\n",
    "model = AdaBoostClassifier().fit(X_train, y_train)\n",
    "\n",
    "# TODO: Extract the feature importances using .feature_importances_ \n",
    "importances = model.feature_importances_ \n",
    "\n",
    "print (importances)\n",
    "# Plot\n",
    "#vs.feature_plot(importances, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_best_features(clf):\n",
    "    model = clf.fit(X_train, y_train)\n",
    "    \n",
    "    importances = model.feature_importances_ \n",
    "    \n",
    "    \n",
    "    feats = {} # a dict to hold feature_name: feature_importance\n",
    "    for feature, importance in zip(train_values_final.columns, model.feature_importances_):\n",
    "        feats[feature] = importance #add the name/value pair \n",
    "\n",
    "    sorted_feats = sorted((v,k) for k,v in feats.items())\n",
    "\n",
    "    print (sorted_feats)    \n",
    "    return sorted_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances for DecisionTreeClassifier:\n",
      "[(0.0, 'agerange_21-40'), (0.0, 'agerange_41-60'), (0.0, 'agerange_61-80'), (0.0, 'exercise_induced_angina'), (0.0, 'fasting_blood_sugar_gt_120_mg_per_dl'), (0.0, 'resting_ekg_results'), (0.0, 'thal_fixed_defect'), (0.0, 'thal_reversible_defect'), (0.0085139318885449032, 'resting_blood_pressure'), (0.021229544449358696, 'sex'), (0.027863777089783284, 'slope_of_peak_exercise_st_segment'), (0.037151702786377715, 'num_major_vessels'), (0.061359045105175113, 'serum_cholesterol_mg_per_dl'), (0.071649712516585584, 'max_heart_rate_achieved'), (0.097543114391926991, 'chest_pain_type'), (0.14937123453014814, 'age'), (0.23409428845290634, 'oldpeak_eq_st_depression'), (0.29122364878919332, 'thal_normal')]\n",
      "[(0.0, 'agerange_21-40'), (0.0, 'agerange_41-60'), (0.0, 'agerange_61-80'), (0.0, 'exercise_induced_angina'), (0.0, 'fasting_blood_sugar_gt_120_mg_per_dl'), (0.0, 'resting_ekg_results'), (0.0, 'thal_fixed_defect'), (0.0, 'thal_reversible_defect'), (0.0085139318885449032, 'resting_blood_pressure'), (0.021229544449358696, 'sex'), (0.027863777089783284, 'slope_of_peak_exercise_st_segment'), (0.037151702786377715, 'num_major_vessels'), (0.061359045105175113, 'serum_cholesterol_mg_per_dl'), (0.071649712516585584, 'max_heart_rate_achieved'), (0.097543114391926991, 'chest_pain_type'), (0.14937123453014814, 'age'), (0.23409428845290634, 'oldpeak_eq_st_depression'), (0.29122364878919332, 'thal_normal')]\n",
      "Feature importances for AdaBoostClassifier :\n",
      "[(0.0, 'agerange_21-40'), (0.0, 'agerange_41-60'), (0.0, 'agerange_61-80'), (0.0, 'thal_fixed_defect'), (0.02, 'fasting_blood_sugar_gt_120_mg_per_dl'), (0.02, 'resting_ekg_results'), (0.02, 'slope_of_peak_exercise_st_segment'), (0.02, 'thal_normal'), (0.02, 'thal_reversible_defect'), (0.040000000000000001, 'chest_pain_type'), (0.040000000000000001, 'exercise_induced_angina'), (0.040000000000000001, 'num_major_vessels'), (0.040000000000000001, 'resting_blood_pressure'), (0.059999999999999998, 'sex'), (0.14000000000000001, 'oldpeak_eq_st_depression'), (0.14000000000000001, 'serum_cholesterol_mg_per_dl'), (0.17999999999999999, 'max_heart_rate_achieved'), (0.22, 'age')]\n",
      "[(0.0, 'agerange_21-40'), (0.0, 'agerange_41-60'), (0.0, 'agerange_61-80'), (0.0, 'thal_fixed_defect'), (0.02, 'fasting_blood_sugar_gt_120_mg_per_dl'), (0.02, 'resting_ekg_results'), (0.02, 'slope_of_peak_exercise_st_segment'), (0.02, 'thal_normal'), (0.02, 'thal_reversible_defect'), (0.040000000000000001, 'chest_pain_type'), (0.040000000000000001, 'exercise_induced_angina'), (0.040000000000000001, 'num_major_vessels'), (0.040000000000000001, 'resting_blood_pressure'), (0.059999999999999998, 'sex'), (0.14000000000000001, 'oldpeak_eq_st_depression'), (0.14000000000000001, 'serum_cholesterol_mg_per_dl'), (0.17999999999999999, 'max_heart_rate_achieved'), (0.22, 'age')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = AdaBoostClassifier()\n",
    "\n",
    "print ('Feature importances for DecisionTreeClassifier:')\n",
    "print (get_best_features(clf1))\n",
    "print ('Feature importances for AdaBoostClassifier :')\n",
    "print (get_best_features(clf2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The top 5 features ranked by features_importances for Decision Tree are:-\n",
    "thal_normal: 0.29\n",
    "oldpeak_eq_st_depression: 0.164\n",
    "age: 0.153\n",
    "chest_pain_type: 0.098\n",
    "serum_cholesterol_mg_per_dl: 0.08\n",
    "\n",
    "The top 5 features ranked by features_importances for Adaboost are:-\n",
    "\n",
    "age: 0.22\n",
    "max_heart_rate_achieved: 0.18\n",
    "serum_cholesterol_mg_per_dl: 0.14\n",
    "oldpeak_eq_st_depression: 0.14\n",
    "sex: 0.06\n",
    "\n",
    "This is different from the corr values we've gotten previously:-\n",
    "thal_normal : -0.528811509654\n",
    "thal_reversible_defect : 0.525145374593\n",
    "exercise_induced_angina : 0.448646516812\n",
    "num_major_vessels : 0.421518626048\n",
    "chest_pain_type : 0.412828625366"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-6b968ba199c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_reduced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test_reduced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "X_train_reduced = X_train[X_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "X_test_reduced = X_test[X_test.columns.values[(np.argsort(importances)[::-1])[:5]]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a62992aa52c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures_train_reduced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfeatures_test_reduced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeatures_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "features_train_reduced = features_train[features_train.columns.values[(np.argsort(importances)[::-1])[:5]]]\n",
    "features_test_reduced = features_test[features_test.columns.values[(np.argsort(importances)[::-1])[:5]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            age  max_heart_rate_achieved  serum_cholesterol_mg_per_dl  \\\n",
      "patient_id                                                              \n",
      "0z64un       45                      170                          308   \n",
      "ryoo3j       54                      158                          214   \n",
      "yt1s1x       77                      162                          304   \n",
      "l2xjde       40                      181                          223   \n",
      "oyt4ek       59                      145                          270   \n",
      "ldukkw       42                      150                          180   \n",
      "2gbyh9       60                      157                          258   \n",
      "daa9kp       57                      112                          276   \n",
      "3nwy2n       59                      140                          326   \n",
      "1r508r       50                      158                          219   \n",
      "ldg4b9       66                      151                          302   \n",
      "xc17yq       42                      178                          226   \n",
      "mpggsq       64                      158                          335   \n",
      "zlyac8       45                      152                          236   \n",
      "f06u72       38                      182                          231   \n",
      "2fv3rc       50                      126                          200   \n",
      "qyrkxn       45                      175                          234   \n",
      "237mql       60                      144                          253   \n",
      "mc750a       29                      202                          204   \n",
      "30v796       58                      152                          319   \n",
      "cvux3j       71                      162                          302   \n",
      "k8899q       52                      147                          233   \n",
      "jhdvtb       67                      142                          223   \n",
      "5g9v0h       66                      138                          228   \n",
      "83asqd       70                      143                          245   \n",
      "gla0im       68                      115                          211   \n",
      "zzmfh7       57                      159                          303   \n",
      "f4g1ay       52                      184                          205   \n",
      "lek9q9       60                      155                          185   \n",
      "8265rl       51                      123                          175   \n",
      "...         ...                      ...                          ...   \n",
      "x4yp0f       54                      156                          309   \n",
      "9at0il       54                      152                          273   \n",
      "nfag5b       35                      130                          198   \n",
      "strmq8       44                      153                          290   \n",
      "43k3gx       62                       97                          263   \n",
      "fz84ac       59                      125                          273   \n",
      "02cipp       69                      151                          239   \n",
      "1ennzl       48                      139                          275   \n",
      "isq8yp       44                      169                          226   \n",
      "ewckbx       60                      132                          206   \n",
      "dtljkq       49                      171                          266   \n",
      "a2kf1z       60                      160                          230   \n",
      "usnkhx       62                      145                          164   \n",
      "hltlsl       45                      147                          309   \n",
      "l0c19s       53                      111                          226   \n",
      "lcexsf       67                      172                          277   \n",
      "y3m2bd       57                      168                          207   \n",
      "qcjf51       46                      144                          249   \n",
      "7zbya5       63                      150                          233   \n",
      "23gf0e       64                      144                          211   \n",
      "qhz9ye       58                      111                          270   \n",
      "u25507       66                      132                          212   \n",
      "j9tw19       39                      140                          219   \n",
      "5o32oi       51                      173                          299   \n",
      "o63ri2       54                      160                          239   \n",
      "5qfar3       67                      163                          254   \n",
      "2s2b1f       55                      117                          327   \n",
      "nsd00i       64                      131                          309   \n",
      "0xw93k       48                      175                          255   \n",
      "2nx10r       54                      163                          201   \n",
      "\n",
      "            oldpeak_eq_st_depression  sex  \n",
      "patient_id                                 \n",
      "0z64un                           0.0    1  \n",
      "ryoo3j                           1.6    0  \n",
      "yt1s1x                           0.0    1  \n",
      "l2xjde                           0.0    1  \n",
      "oyt4ek                           4.2    1  \n",
      "ldukkw                           0.0    1  \n",
      "2gbyh9                           2.6    0  \n",
      "daa9kp                           0.6    1  \n",
      "3nwy2n                           3.4    1  \n",
      "1r508r                           1.6    0  \n",
      "ldg4b9                           0.4    1  \n",
      "xc17yq                           0.0    1  \n",
      "mpggsq                           0.0    1  \n",
      "zlyac8                           0.2    0  \n",
      "f06u72                           3.8    1  \n",
      "2fv3rc                           0.9    1  \n",
      "qyrkxn                           0.6    0  \n",
      "237mql                           1.4    1  \n",
      "mc750a                           0.0    1  \n",
      "30v796                           0.0    0  \n",
      "cvux3j                           0.4    0  \n",
      "k8899q                           0.1    1  \n",
      "jhdvtb                           0.3    0  \n",
      "5g9v0h                           2.3    1  \n",
      "83asqd                           0.0    1  \n",
      "gla0im                           1.5    0  \n",
      "zzmfh7                           0.0    0  \n",
      "f4g1ay                           0.0    1  \n",
      "lek9q9                           3.0    1  \n",
      "8265rl                           0.6    1  \n",
      "...                              ...  ...  \n",
      "x4yp0f                           0.0    1  \n",
      "9at0il                           0.5    1  \n",
      "nfag5b                           1.6    1  \n",
      "strmq8                           0.0    1  \n",
      "43k3gx                           1.2    0  \n",
      "fz84ac                           0.0    1  \n",
      "02cipp                           1.8    0  \n",
      "1ennzl                           0.2    0  \n",
      "isq8yp                           0.0    1  \n",
      "ewckbx                           2.4    1  \n",
      "dtljkq                           0.6    1  \n",
      "a2kf1z                           1.4    1  \n",
      "usnkhx                           6.2    0  \n",
      "hltlsl                           0.0    1  \n",
      "l0c19s                           0.0    1  \n",
      "lcexsf                           0.0    0  \n",
      "y3m2bd                           0.0    1  \n",
      "qcjf51                           0.8    1  \n",
      "7zbya5                           2.3    1  \n",
      "23gf0e                           1.8    1  \n",
      "qhz9ye                           0.8    1  \n",
      "u25507                           0.1    1  \n",
      "j9tw19                           1.2    1  \n",
      "5o32oi                           1.6    1  \n",
      "o63ri2                           1.2    1  \n",
      "5qfar3                           0.2    1  \n",
      "2s2b1f                           3.4    0  \n",
      "nsd00i                           1.8    1  \n",
      "0xw93k                           0.0    1  \n",
      "2nx10r                           0.0    0  \n",
      "\n",
      "[180 rows x 5 columns]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-0f9ebe8328ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_values_reduced\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_values_final\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_values_final\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_values_reduced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "train_reduced = train_values_final[train_values_final.columns.values[[(np.argsort(importances)[::-1])[:5]]]]\n",
    "print (train_values_reduced).head(5)\n",
    "\n",
    "# it print out the adaboost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.41860465  0.66666667  0.          0.          0.\n",
      "  0.24429224  0.06451613  1.          0.3125      0.78301887  1.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.39534884  1.          0.66666667  0.          1.\n",
      "  0.30365297  0.48387097  1.          0.60416667  0.32075472  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.34883721  0.33333333  0.          0.          0.\n",
      "  0.30821918  0.0483871   1.          0.58333333  0.4245283   0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.55813953  1.          1.          0.          1.\n",
      "  0.41780822  0.          1.          0.33333333  0.48113208  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.41860465  0.66666667  1.          1.          1.          0.2739726\n",
      "  0.          1.          0.5         0.72641509  0.          0.          1.\n",
      "  0.          0.          1.          0.        ]\n",
      "[ 0.          0.72093023  0.33333333  0.          0.          1.          0.2716895\n",
      "  0.          1.          0.85416667  0.44339623  0.          0.          1.\n",
      "  0.          0.          0.          1.        ]\n",
      "[ 0.5         0.41860465  0.66666667  0.          0.          1.\n",
      "  0.20091324  0.32258065  1.          0.25        0.67924528  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.27906977  0.66666667  0.33333333  0.          0.\n",
      "  0.34474886  0.16129032  1.          0.8125      0.51886792  0.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.41860465  1.          0.          0.          1.\n",
      "  0.46575342  0.          0.          0.66666667  0.68867925  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 1.          0.41860465  0.66666667  0.          1.          1.\n",
      "  0.16210046  0.19354839  1.          0.5         0.52830189  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.48837209  0.33333333  0.66666667  1.          1.\n",
      "  0.44063927  0.          0.          0.60416667  0.52830189  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.65116279  1.          0.          0.          0.\n",
      "  0.26940639  0.22580645  0.          0.6875      0.54716981  1.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.53488372  0.66666667  0.          0.          0.\n",
      "  0.42694064  0.03225806  0.          0.72916667  0.3490566   0.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.53488372  0.          0.          0.          0.\n",
      "  0.16666667  0.22580645  1.          0.22916667  0.77358491  1.          0.\n",
      "  0.          1.          1.          0.          0.        ]\n",
      "[ 0.5         0.41860465  0.33333333  0.          0.          1.\n",
      "  0.24657534  0.09677419  0.          0.33333333  0.74528302  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.41860465  0.66666667  0.33333333  0.          0.\n",
      "  0.43150685  0.30645161  1.          0.29166667  0.62264151  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.65116279  1.          0.          0.          1.\n",
      "  0.32876712  0.12903226  1.          0.60416667  0.14150943  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.27906977  0.33333333  0.          0.          0.\n",
      "  0.19178082  0.11290323  0.          0.10416667  0.90566038  0.          0.\n",
      "  1.          0.          1.          0.          0.        ]\n",
      "[ 0.5         0.65116279  0.66666667  0.          1.          0.\n",
      "  0.26712329  0.16129032  1.          0.66666667  0.38679245  1.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.5         0.37209302  0.66666667  0.33333333  1.          0.\n",
      "  0.21004566  0.35483871  1.          0.625       0.35849057  0.          1.\n",
      "  0.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.13953488  1.          0.66666667  0.          0.\n",
      "  0.22146119  0.0483871   0.          0.79166667  0.43396226  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.5         0.39534884  1.          0.33333333  0.          0.\n",
      "  0.31278539  0.03225806  1.          0.72916667  0.08490566  1.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.30232558  0.33333333  0.          0.          0.\n",
      "  0.26940639  0.17741935  0.          0.4375      0.62264151  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 1.          0.30232558  1.          0.33333333  0.          1.          0.2739726\n",
      "  0.35483871  1.          0.72916667  0.          1.          0.          1.\n",
      "  0.          0.          0.          1.        ]\n",
      "[ 0.5         0.59302326  1.          0.66666667  0.          1.\n",
      "  0.19634703  0.32258065  1.          0.72916667  0.33962264  0.          1.\n",
      "  0.          0.          0.          0.          1.        ]\n",
      "[ 0.5         0.46511628  0.33333333  0.          0.          0.\n",
      "  0.33105023  0.          0.          0.41666667  0.62264151  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.47674419  0.33333333  0.          0.          0.\n",
      "  0.17579909  0.          1.          0.25        0.33962264  0.          1.\n",
      "  0.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.39534884  0.33333333  0.          1.          0.          0.1803653\n",
      "  0.          1.          0.47916667  0.83018868  0.          0.          1.\n",
      "  0.          0.          1.          0.        ]\n",
      "[ 0.5         0.1627907   0.66666667  0.          0.          0.\n",
      "  0.03424658  0.09677419  0.          0.3125      0.74528302  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.41860465  0.66666667  0.          0.          0.\n",
      "  0.34018265  0.03225806  0.          0.39583333  0.40566038  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.          0.66666667  0.33333333  0.          0.\n",
      "  0.23059361  0.          1.          0.45833333  0.54716981  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         1.          1.          0.          0.          0.5\n",
      "  0.45890411  0.5483871   0.          0.54166667  0.19811321  1.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.41860465  0.33333333  0.          0.          0.\n",
      "  0.31050228  0.          1.          0.54166667  0.55660377  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 1.          0.41860465  1.          0.          1.          1.\n",
      "  0.35844749  0.25806452  1.          0.5625      0.06603774  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.36046512  1.          1.          0.          1.\n",
      "  0.40639269  0.          1.          1.          0.62264151  1.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.18604651  1.          0.33333333  0.          1.\n",
      "  0.16210046  0.          1.          0.3125      0.76415094  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.76744186  0.          0.33333333  1.          1.\n",
      "  0.24657534  0.01612903  1.          0.83333333  0.33018868  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.70930233  0.66666667  0.          0.          0.\n",
      "  0.32648402  0.12903226  0.          0.75        0.49056604  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.53488372  0.66666667  0.33333333  1.          1.\n",
      "  0.66438356  0.12903226  0.          0.75        0.5754717   0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.5         0.30232558  1.          0.          0.          1.\n",
      "  0.40182648  0.06451613  1.          0.77083333  0.51886792  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.20930233  0.66666667  0.          0.          1.\n",
      "  0.32420091  0.          0.          0.25        0.71698113  1.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.30232558  0.66666667  0.          0.          0.\n",
      "  0.20319635  0.          0.          0.16666667  0.69811321  0.          0.\n",
      "  1.          0.          1.          0.          0.        ]\n",
      "[ 0.          0.53488372  1.          0.          0.          0.\n",
      "  0.39497717  0.25806452  1.          0.45833333  0.72641509  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.26744186  1.          0.66666667  1.          0.\n",
      "  0.23744292  0.22580645  1.          0.64583333  0.60377358  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.53488372  1.          1.          0.          0.\n",
      "  0.39269406  0.67741935  1.          0.45833333  0.24528302  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.53488372  0.66666667  0.          0.          1.\n",
      "  0.24885845  0.          1.          0.3125      0.79245283  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.53488372  1.          0.66666667  0.          1.\n",
      "  0.38127854  0.19354839  1.          0.64583333  0.69811321  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.1627907   0.33333333  0.          0.          0.\n",
      "  0.41780822  0.          1.          0.52083333  0.56603774  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.76744186  0.66666667  0.33333333  0.          0.\n",
      "  0.17123288  0.          0.          0.52083333  0.63207547  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.53488372  1.          0.66666667  0.          0.\n",
      "  0.42237443  0.29032258  1.          0.35416667  0.22641509  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.36046512  0.66666667  0.          0.          0.\n",
      "  0.41780822  0.29032258  1.          0.72916667  0.33018868  1.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.5         0.44186047  1.          0.33333333  0.          0.\n",
      "  0.51826484  0.19354839  1.          0.54166667  0.33962264  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.18604651  1.          0.          0.          1.\n",
      "  0.29223744  0.          0.          0.4375      0.59433962  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.76744186  1.          1.          0.          1.          0.3652968\n",
      "  0.24193548  1.          0.79166667  0.11320755  1.          0.          1.\n",
      "  0.          0.          0.          1.        ]\n",
      "[ 0.5         0.09302326  1.          0.          0.          1.          0.3173516\n",
      "  0.09677419  0.          0.27083333  0.24528302  0.          0.          1.\n",
      "  0.          0.          1.          0.        ]\n",
      "[ 0.5         0.30232558  0.66666667  1.          0.          0.\n",
      "  0.14155251  0.32258065  1.          0.41666667  0.40566038  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.12790698  0.33333333  0.          0.          0.\n",
      "  0.17808219  0.          0.          0.35416667  0.71698113  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.30232558  0.33333333  0.33333333  0.          1.\n",
      "  0.35388128  0.22580645  1.          0.6875      0.06603774  0.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.27906977  0.66666667  1.          0.          1.\n",
      "  0.05251142  0.12903226  1.          0.41666667  0.28301887  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.51162791  1.          0.          0.          1.\n",
      "  0.25114155  0.03225806  0.          0.33333333  0.52830189  1.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.30232558  1.          0.          0.          0.\n",
      "  0.11643836  0.06451613  1.          0.75        0.41509434  0.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.76744186  1.          0.          0.          1.\n",
      "  0.23287671  0.37096774  1.          0.77083333  0.39622642  0.          1.\n",
      "  0.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.30232558  1.          0.          0.          1.\n",
      "  0.28082192  0.12903226  1.          0.35416667  0.45283019  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.76744186  0.33333333  0.66666667  0.          0.\n",
      "  0.40182648  0.06451613  0.          0.875       0.62264151  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.5         0.58139535  1.          0.          0.          1.\n",
      "  0.16894977  0.14516129  1.          0.4375      0.28301887  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.59302326  1.          0.66666667  0.          1.\n",
      "  0.35616438  0.4516129   1.          0.64583333  0.43396226  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.41860465  1.          1.          1.          1.\n",
      "  0.46575342  0.29032258  1.          0.70833333  0.33962264  1.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.53488372  0.66666667  0.          0.          1.\n",
      "  0.44520548  0.          1.          0.20833333  0.81132075  0.          0.\n",
      "  1.          0.          1.          0.          0.        ]\n",
      "[ 0.5         0.48837209  0.66666667  0.          0.          1.\n",
      "  0.15981735  0.01612903  0.          0.47916667  0.68867925  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.6744186   1.          0.          0.          0.\n",
      "  0.22146119  0.          1.          0.22916667  0.80188679  0.          0.\n",
      "  0.          1.          1.          0.          0.        ]\n",
      "[ 0.          0.34883721  0.66666667  0.66666667  1.          0.\n",
      "  0.29452055  0.          1.          0.39583333  0.74528302  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.34883721  1.          0.          0.          1.\n",
      "  0.33789954  0.08064516  1.          0.39583333  0.66037736  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.65116279  1.          0.66666667  0.          1.\n",
      "  0.30136986  0.41935484  0.          0.64583333  0.5754717   0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.47674419  0.33333333  0.          0.          1.\n",
      "  0.28310502  0.22580645  0.          0.54166667  0.61320755  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.97674419  1.          0.66666667  1.          0.\n",
      "  0.23287671  0.16129032  0.          0.77083333  0.6509434   1.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.41860465  0.66666667  0.          0.          1.\n",
      "  0.29680365  0.08064516  0.          0.45833333  0.5         0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.36046512  1.          0.66666667  0.          1.\n",
      "  0.39726027  0.          1.          0.60416667  0.70754717  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.53488372  0.66666667  0.          0.          0.\n",
      "  0.47716895  0.          1.          0.72916667  0.58490566  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.41860465  0.33333333  0.          0.          1.\n",
      "  0.21232877  0.          1.          0.3125      0.86792453  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.41860465  0.66666667  0.33333333  0.          0.\n",
      "  0.31278539  0.19354839  0.          0.6875      0.00943396  0.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.5         0.30232558  0.          0.          0.          0.\n",
      "  0.23972603  0.61290323  1.          0.1875      0.81132075  1.          0.\n",
      "  0.          1.          1.          0.          0.        ]\n",
      "[ 0.          0.39534884  0.33333333  0.          0.          1.\n",
      "  0.41552511  0.          1.          0.33333333  0.69811321  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.06976744  1.          0.66666667  0.          1.\n",
      "  0.39497717  0.14516129  1.          0.79166667  0.27358491  1.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.76744186  0.          0.          0.          1.\n",
      "  0.33561644  0.          1.          0.625       0.27358491  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.36046512  0.66666667  0.          1.          1.          0.2716895\n",
      "  0.38709677  1.          0.45833333  0.66037736  0.          0.          1.\n",
      "  0.          0.          1.          0.        ]\n",
      "[ 0.          0.53488372  1.          0.          0.          0.          0.2283105\n",
      "  0.          1.          0.27083333  0.77358491  0.          0.          1.\n",
      "  0.          0.          1.          0.        ]\n",
      "[ 0.5         0.51162791  1.          1.          1.          0.\n",
      "  0.38356164  0.30645161  0.          0.6875      0.09433962  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.5         0.18604651  1.          0.33333333  0.          1.\n",
      "  0.25799087  0.19354839  1.          0.625       0.43396226  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.3255814   1.          0.          0.          1.\n",
      "  0.21917808  0.          1.          0.39583333  0.8490566   0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.30232558  1.          0.66666667  0.          0.\n",
      "  0.32191781  0.29032258  1.          0.6875      0.02830189  1.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.47674419  0.66666667  0.          0.          1.\n",
      "  0.28767123  0.          0.          0.70833333  0.71698113  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.5         0.36046512  1.          0.66666667  1.          0.\n",
      "  0.29223744  0.03225806  1.          0.79166667  0.63207547  0.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.37209302  1.          0.          0.          1.\n",
      "  0.35616438  0.          1.          0.125       0.56603774  1.          0.\n",
      "  0.          1.          1.          0.          0.        ]\n",
      "[ 0.5         0.18604651  0.66666667  0.          0.          0.\n",
      "  0.20091324  0.25806452  0.          0.52083333  0.58490566  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.51162791  0.          0.33333333  1.          1.\n",
      "  0.35616438  0.22580645  1.          0.75        0.73584906  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.53488372  0.33333333  0.66666667  0.          0.\n",
      "  0.15753425  0.          0.          0.70833333  0.78301887  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.18604651  0.66666667  0.33333333  1.          1.          0.3173516\n",
      "  0.          0.          0.875       0.32075472  0.          0.          1.\n",
      "  0.          0.          0.          1.        ]\n",
      "[ 0.5         0.41860465  1.          0.66666667  0.          0.\n",
      "  0.40410959  0.32258065  0.          0.72916667  0.24528302  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.41860465  0.33333333  0.          0.          1.\n",
      "  0.17808219  0.22580645  0.          0.25        0.71698113  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.53488372  0.          0.66666667  0.          0.\n",
      "  0.25799087  0.29032258  0.          0.83333333  0.51886792  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.41860465  1.          0.33333333  0.          0.\n",
      "  0.28995434  0.22580645  1.          0.64583333  0.45283019  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.30232558  0.33333333  0.33333333  0.          1.\n",
      "  0.32648402  0.03225806  0.          0.9375      0.23584906  1.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.44186047  0.66666667  0.66666667  0.          1.\n",
      "  0.22374429  0.51612903  1.          0.60416667  0.72641509  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.41860465  0.66666667  0.33333333  1.          1.\n",
      "  0.29680365  0.09677419  1.          0.5625      0.43396226  1.          1.\n",
      "  0.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.30232558  0.          0.          0.          1.\n",
      "  0.15296804  0.30645161  1.          0.5625      0.62264151  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 1.          0.59302326  1.          0.          0.          0.\n",
      "  0.10958904  0.41935484  1.          0.85416667  0.27358491  1.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.5         0.20930233  0.66666667  0.33333333  0.          1.\n",
      "  0.23744292  0.40322581  1.          0.60416667  0.6509434   0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.53488372  0.66666667  0.          0.          1.          0.1347032\n",
      "  0.48387097  1.          0.64583333  0.55660377  0.          0.          1.\n",
      "  0.          0.          1.          0.        ]\n",
      "[ 0.          0.20930233  0.66666667  0.          0.          0.\n",
      "  0.28310502  0.          1.          0.25        0.78301887  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.65116279  1.          1.          0.          1.          0.2260274\n",
      "  0.16129032  0.          0.75        0.16981132  0.          0.          0.\n",
      "  1.          0.          0.          1.        ]\n",
      "[ 0.5         0.39534884  0.66666667  0.33333333  0.          1.\n",
      "  0.23515982  0.06451613  1.          0.58333333  0.50943396  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.30232558  0.66666667  0.          0.          1.\n",
      "  0.30136986  0.06451613  1.          0.52083333  0.48113208  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.41860465  1.          0.66666667  0.          1.          0.1826484\n",
      "  0.38709677  1.          0.64583333  0.33962264  1.          0.          0.\n",
      "  1.          0.          1.          0.        ]\n",
      "[ 1.          0.53488372  1.          0.          1.          1.\n",
      "  0.17579909  0.5         1.          0.5         0.55660377  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.30232558  0.33333333  0.          0.          0.\n",
      "  0.31278539  0.          1.          0.3125      0.72641509  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.30232558  1.          0.          0.          0.\n",
      "  0.16438356  0.25806452  1.          0.125       0.32075472  1.          0.\n",
      "  0.          1.          1.          0.          0.        ]\n",
      "[ 0.5         0.46511628  0.          0.66666667  0.          0.\n",
      "  0.24657534  0.41935484  1.          0.66666667  0.46226415  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.18604651  0.66666667  0.          0.          0.\n",
      "  0.11187215  0.09677419  1.          0.45833333  0.25471698  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.65116279  0.          0.          1.          1.\n",
      "  0.35844749  0.16129032  0.          0.60416667  0.62264151  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 1.          0.18604651  0.33333333  0.          0.          0.\n",
      "  0.23515982  0.16129032  1.          0.39583333  0.67924528  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.41860465  1.          0.33333333  0.          1.\n",
      "  0.29223744  0.22580645  1.          0.70833333  0.48113208  0.          0.\n",
      "  0.          1.          0.          0.          1.        ]\n",
      "[ 0.          0.53488372  0.66666667  0.          1.          1.\n",
      "  0.19406393  0.          1.          0.60416667  0.6509434   0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.1627907   0.66666667  0.          0.          0.\n",
      "  0.26712329  0.          1.          0.375       0.52830189  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.53488372  1.          0.          0.          0.\n",
      "  0.25799087  0.19354839  1.          0.52083333  0.60377358  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.90697674  0.66666667  0.          1.          0.\n",
      "  0.16666667  0.08064516  1.          0.47916667  0.62264151  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.34883721  1.          0.33333333  0.          1.          0.3196347\n",
      "  0.35483871  1.          0.52083333  0.12264151  1.          0.          0.\n",
      "  1.          0.          1.          0.        ]\n",
      "[ 0.5         0.30232558  0.66666667  0.          0.          1.\n",
      "  0.19406393  0.24193548  0.          0.8125      0.17924528  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.5         0.30232558  1.          0.33333333  0.          0.\n",
      "  0.14155251  0.22580645  1.          0.52083333  0.16037736  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.18604651  0.          0.          0.          1.\n",
      "  0.19406393  0.29032258  1.          0.72916667  0.45283019  1.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.20930233  1.          0.33333333  0.          1.\n",
      "  0.19634703  0.01612903  1.          0.77083333  0.33962264  1.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.          0.39534884  1.          0.33333333  0.          0.\n",
      "  0.29452055  0.          1.          0.47916667  0.61320755  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.30232558  0.33333333  0.          0.          0.\n",
      "  0.38584475  0.          1.          0.27083333  0.62264151  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 1.          0.53488372  1.          0.          0.          0.\n",
      "  0.20776256  0.90322581  1.          0.54166667  0.14150943  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.65116279  0.66666667  0.          0.          0.\n",
      "  0.09589041  0.25806452  1.          0.58333333  0.73584906  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.30232558  0.33333333  0.          0.          0.\n",
      "  0.21461187  0.          1.          0.3125      0.69811321  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.53488372  1.          0.33333333  0.          0.\n",
      "  0.11643836  0.          1.          0.625       0.62264151  1.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.          0.65116279  0.66666667  0.33333333  1.          0.          0.\n",
      "  0.03225806  1.          0.58333333  0.72641509  0.          0.          0.\n",
      "  1.          0.          1.          0.        ]\n",
      "[ 0.          0.1627907   1.          1.          1.          0.\n",
      "  0.24429224  0.01612903  1.          0.47916667  0.48113208  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.30232558  0.66666667  0.          0.          0.\n",
      "  0.21232877  0.25806452  0.          0.4375      0.58490566  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.53488372  0.66666667  0.33333333  0.          1.\n",
      "  0.41552511  0.24193548  0.          0.45833333  0.43396226  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.5         0.24418605  1.          0.          0.          0.\n",
      "  0.40410959  0.19354839  1.          0.29166667  0.80188679  0.          0.\n",
      "  1.          0.          0.          1.          0.        ]\n",
      "[ 0.          0.18604651  1.          0.          0.          1.\n",
      "  0.10502283  0.          1.          0.25        0.58490566  0.          0.\n",
      "  0.          1.          0.          1.          0.        ]\n",
      "[ 0.5         0.20930233  1.          0.          0.          0.\n",
      "  0.05251142  0.25806452  0.          0.875       0.27358491  0.          0.\n",
      "  1.          0.          0.          0.          1.        ]\n",
      "[ 0.5         0.27906977  1.          0.          0.          0.\n",
      "  0.21232877  0.19354839  1.          0.20833333  0.41509434  0.          0.\n",
      "  0.          1.          1.          0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "for i in X_train:\n",
    "    print (i)\n",
    "#print (X_train[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  6.02770083   0.08662046   3.18246421   9.16038709   0.10414861\n",
      "   1.25875208   0.09558938   3.67244935   5.07767526   0.25861585\n",
      "   1.68981738  18.44525753   0.32755418  18.92953717  23.30154799\n",
      "   0.25077399   0.17150342   0.13622291]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "selector = SelectKBest(chi2, k='all').fit(X_train,y_train)\n",
    "x_new = selector.transform(X_test) # not needed to get the score\n",
    "scores_skb = selector.scores_\n",
    "\n",
    "print (scores_skb)\n",
    "\n",
    "#X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[ True False False  True False False False  True False False False  True\n",
      " False  True False False False False]\n",
      "True slope_of_peak_exercise_st_segment\n",
      "False resting_blood_pressure\n",
      "False chest_pain_type\n",
      "True num_major_vessels\n",
      "False fasting_blood_sugar_gt_120_mg_per_dl\n",
      "False resting_ekg_results\n",
      "False serum_cholesterol_mg_per_dl\n",
      "True oldpeak_eq_st_depression\n",
      "False sex\n",
      "False age\n",
      "False max_heart_rate_achieved\n",
      "True exercise_induced_angina\n",
      "False thal_fixed_defect\n",
      "True thal_normal\n",
      "False thal_reversible_defect\n",
      "False agerange_21-40\n",
      "False agerange_41-60\n",
      "False agerange_61-80\n",
      "['slope_of_peak_exercise_st_segment', 'num_major_vessels', 'oldpeak_eq_st_depression', 'exercise_induced_angina', 'thal_normal']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model_lr=LogisticRegression()\n",
    "rfe = RFE(model_lr, 5)\n",
    "fit = rfe.fit(X_train, y_train)\n",
    "\n",
    "col_list=[]\n",
    "print (fit.n_features_)\n",
    "print (fit.support_)\n",
    "    \n",
    "for bool, feature in zip(fit.support_, train_values_final.columns):\n",
    "    print (bool, feature)\n",
    "    if bool:\n",
    "        col_list.append(feature)\n",
    "\n",
    "print (col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.39534884  0.33333333 ...,  0.          1.          0.        ]\n",
      " [ 0.5         0.18604651  0.66666667 ...,  0.          1.          0.        ]\n",
      " [ 0.          0.36046512  1.         ...,  0.          0.          1.        ]\n",
      " ..., \n",
      " [ 0.5         0.36046512  0.66666667 ...,  0.          0.          1.        ]\n",
      " [ 0.          0.34883721  0.66666667 ...,  0.          1.          0.        ]\n",
      " [ 0.          0.76744186  0.66666667 ...,  0.          1.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print (features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            slope_of_peak_exercise_st_segment  num_major_vessels  \\\n",
      "patient_id                                                         \n",
      "0z64un                                      1                  0   \n",
      "ryoo3j                                      2                  0   \n",
      "yt1s1x                                      1                  3   \n",
      "l2xjde                                      1                  0   \n",
      "oyt4ek                                      3                  0   \n",
      "ldukkw                                      1                  0   \n",
      "2gbyh9                                      2                  2   \n",
      "daa9kp                                      2                  1   \n",
      "3nwy2n                                      3                  0   \n",
      "1r508r                                      2                  0   \n",
      "ldg4b9                                      2                  0   \n",
      "xc17yq                                      1                  0   \n",
      "mpggsq                                      1                  0   \n",
      "zlyac8                                      2                  0   \n",
      "f06u72                                      2                  0   \n",
      "2fv3rc                                      2                  0   \n",
      "qyrkxn                                      2                  0   \n",
      "237mql                                      1                  1   \n",
      "mc750a                                      1                  0   \n",
      "30v796                                      1                  2   \n",
      "cvux3j                                      1                  2   \n",
      "k8899q                                      1                  3   \n",
      "jhdvtb                                      1                  2   \n",
      "5g9v0h                                      1                  0   \n",
      "83asqd                                      1                  0   \n",
      "gla0im                                      2                  0   \n",
      "zzmfh7                                      1                  1   \n",
      "f4g1ay                                      1                  0   \n",
      "lek9q9                                      2                  0   \n",
      "8265rl                                      1                  0   \n",
      "...                                       ...                ...   \n",
      "x4yp0f                                      1                  0   \n",
      "9at0il                                      3                  1   \n",
      "nfag5b                                      2                  0   \n",
      "strmq8                                      1                  1   \n",
      "43k3gx                                      2                  1   \n",
      "fz84ac                                      1                  0   \n",
      "02cipp                                      1                  2   \n",
      "1ennzl                                      1                  0   \n",
      "isq8yp                                      1                  0   \n",
      "ewckbx                                      2                  2   \n",
      "dtljkq                                      1                  0   \n",
      "a2kf1z                                      1                  2   \n",
      "usnkhx                                      3                  3   \n",
      "hltlsl                                      2                  3   \n",
      "l0c19s                                      1                  0   \n",
      "lcexsf                                      1                  1   \n",
      "y3m2bd                                      1                  0   \n",
      "qcjf51                                      1                  0   \n",
      "7zbya5                                      3                  0   \n",
      "23gf0e                                      2                  0   \n",
      "qhz9ye                                      1                  0   \n",
      "u25507                                      1                  1   \n",
      "j9tw19                                      2                  0   \n",
      "5o32oi                                      1                  0   \n",
      "o63ri2                                      1                  0   \n",
      "5qfar3                                      2                  2   \n",
      "2s2b1f                                      2                  0   \n",
      "nsd00i                                      2                  0   \n",
      "0xw93k                                      1                  2   \n",
      "2nx10r                                      1                  1   \n",
      "\n",
      "            oldpeak_eq_st_depression  exercise_induced_angina  thal_normal  \n",
      "patient_id                                                                  \n",
      "0z64un                           0.0                        0            1  \n",
      "ryoo3j                           1.6                        0            1  \n",
      "yt1s1x                           0.0                        1            1  \n",
      "l2xjde                           0.0                        0            0  \n",
      "oyt4ek                           4.2                        0            0  \n",
      "ldukkw                           0.0                        0            1  \n",
      "2gbyh9                           2.6                        0            0  \n",
      "daa9kp                           0.6                        1            0  \n",
      "3nwy2n                           3.4                        1            0  \n",
      "1r508r                           1.6                        0            1  \n",
      "ldg4b9                           0.4                        0            1  \n",
      "xc17yq                           0.0                        0            1  \n",
      "mpggsq                           0.0                        0            1  \n",
      "zlyac8                           0.2                        1            1  \n",
      "f06u72                           3.8                        1            0  \n",
      "2fv3rc                           0.9                        1            0  \n",
      "qyrkxn                           0.6                        0            1  \n",
      "237mql                           1.4                        1            0  \n",
      "mc750a                           0.0                        0            1  \n",
      "30v796                           0.0                        0            1  \n",
      "cvux3j                           0.4                        0            1  \n",
      "k8899q                           0.1                        0            0  \n",
      "jhdvtb                           0.3                        0            1  \n",
      "5g9v0h                           2.3                        0            0  \n",
      "83asqd                           0.0                        0            1  \n",
      "gla0im                           1.5                        0            1  \n",
      "zzmfh7                           0.0                        0            1  \n",
      "f4g1ay                           0.0                        0            1  \n",
      "lek9q9                           3.0                        0            1  \n",
      "8265rl                           0.6                        0            1  \n",
      "...                              ...                      ...          ...  \n",
      "x4yp0f                           0.0                        0            0  \n",
      "9at0il                           0.5                        0            1  \n",
      "nfag5b                           1.6                        1            0  \n",
      "strmq8                           0.0                        0            1  \n",
      "43k3gx                           1.2                        0            0  \n",
      "fz84ac                           0.0                        0            1  \n",
      "02cipp                           1.8                        0            1  \n",
      "1ennzl                           0.2                        0            1  \n",
      "isq8yp                           0.0                        0            1  \n",
      "ewckbx                           2.4                        1            0  \n",
      "dtljkq                           0.6                        0            1  \n",
      "a2kf1z                           1.4                        1            0  \n",
      "usnkhx                           6.2                        0            0  \n",
      "hltlsl                           0.0                        1            0  \n",
      "l0c19s                           0.0                        1            0  \n",
      "lcexsf                           0.0                        0            1  \n",
      "y3m2bd                           0.0                        1            0  \n",
      "qcjf51                           0.8                        0            0  \n",
      "7zbya5                           2.3                        0            0  \n",
      "23gf0e                           1.8                        1            1  \n",
      "qhz9ye                           0.8                        1            0  \n",
      "u25507                           0.1                        1            1  \n",
      "j9tw19                           1.2                        0            0  \n",
      "5o32oi                           1.6                        1            0  \n",
      "o63ri2                           1.2                        0            1  \n",
      "5qfar3                           0.2                        0            0  \n",
      "2s2b1f                           3.4                        1            1  \n",
      "nsd00i                           1.8                        1            0  \n",
      "0xw93k                           0.0                        0            1  \n",
      "2nx10r                           0.0                        0            1  \n",
      "\n",
      "[180 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "reduced_features_trains = train_values_final[col_list]\n",
    "reduced_features_test = test_values_final[col_list]\n",
    "\n",
    "print (reduced_features_trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# minmax scaler again\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "features_train = scaler.fit_transform(train_values_final)\n",
    "features_test = scaler.fit_transform(test_values_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 144 samples.\n",
      "Testing set has 36 samples.\n"
     ]
    }
   ],
   "source": [
    "X_train_reduced, X_test_reduced, y_train_reduced, y_test_reduced = train_test_split(features_train, \n",
    "                                                    train_labels, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (36, 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-b81e452edd7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# gaussian nb with reduced data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgauss_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_reduced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_reduced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_reduced\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test_reduced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-bd493d88c744>\u001b[0m in \u001b[0;36mgauss_\u001b[1;34m(features_train, labels_train, features_test, labels_test)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mclf_Gauss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mclf_Gauss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf_Gauss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m         \"\"\"\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[0;32m    185\u001b[0m                                  sample_weight=sample_weight)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m                         dtype=None)\n\u001b[0;32m    577\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    612\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 614\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    615\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (36, 18)"
     ]
    }
   ],
   "source": [
    "# gaussian nb with reduced data\n",
    "\n",
    "gauss_(X_train_reduced, X_test_reduced, y_train_reduced, y_test_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss score for Decision Tree with no parameter tuning: 15.3505672866\n"
     ]
    }
   ],
   "source": [
    "#dt with reduced data\n",
    "\n",
    "dt_(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss score for KNN with no parameter tuning: 1.26710858796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#knn with reduced data\n",
    "\n",
    "knn_(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_loss score for Logistic Regression with no parameter tuning: 0.393955341314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#logisticregression with reduced data\n",
    "\n",
    "lr_(X_train, y_train, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained Variance: %s [ 0.26963754  0.2002297   0.11728868]\n",
      "[[ 0.11249734 -0.00527823  0.16024216  0.08678522 -0.01261981 -0.05335934\n",
      "  -0.00474093  0.07073169  0.35057158 -0.02121074 -0.06914795  0.30678767\n",
      "   0.00947502 -0.58980137  0.58032634  0.03120142  0.121568   -0.15276943]\n",
      " [ 0.09041725  0.04537025  0.08037813  0.17062808  0.02822474 -0.02637747\n",
      "   0.03228893  0.03986752 -0.08483559  0.2042798  -0.15049536  0.19646026\n",
      "   0.00869018 -0.08748767  0.07879749  0.01896212 -0.65190478  0.63294266]\n",
      " [-0.13595922 -0.02650109 -0.10634395 -0.12390065 -0.14262781 -0.90834987\n",
      "  -0.03283524 -0.03595843 -0.11261535 -0.08352606  0.07687955 -0.17903649\n",
      "  -0.02837018 -0.07152961  0.09989979  0.13692946 -0.11688917 -0.02004029]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# feature extraction\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(X_train)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\",  fit.explained_variance_ratio_)\n",
    "print(fit.components_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Dimension 1  Dimension 2  Dimension 3  Dimension 4  Dimension 5\n",
      "0      -0.151314    -0.549372     0.314838     0.700663     0.721709\n",
      "1       1.188255    -0.076981    -0.684423     0.377794    -0.026895\n",
      "2       0.676580    -0.498808     0.650900    -0.381650    -0.252101\n",
      "3       1.176212    -0.107786    -0.681435     0.297915     0.006360\n",
      "4      -0.442063    -0.528150    -0.699671    -0.708137     0.657547\n",
      "5      -0.833507     0.659637    -0.360123    -0.357766    -0.124418\n",
      "6      -0.428252    -0.715264    -0.493068     0.022196    -0.033597\n",
      "7       0.481382     0.904840     0.655701    -0.581130    -0.302474\n",
      "8      -1.089558     0.715391    -0.282246     0.082705    -0.568834\n",
      "9      -0.388431    -0.574442    -0.730247    -0.407857     0.554085\n",
      "10     -0.864646    -0.467342    -0.541561    -0.402772     0.200190\n",
      "11     -0.648145     1.022203     0.358633     0.934553     0.246004\n",
      "12      0.104525     0.950449     0.798684    -0.211950    -0.762997\n",
      "13      0.835201     0.227790     0.810885     0.274794    -0.022718\n",
      "14     -0.854760    -0.657664    -0.340268     0.236840    -0.454097\n",
      "15     -0.401417    -0.653386     0.427138    -0.014193     0.339803\n",
      "16      1.059976    -0.210695    -0.542468     0.404525    -0.138010\n",
      "17     -0.952108    -0.084035     0.926269     0.266344    -0.353765\n",
      "18     -0.356628     0.956034     0.130643     0.103285     1.226132\n",
      "19      0.257401    -0.383260     0.218304    -0.714791     0.734102\n",
      "20     -0.957327     0.900769     0.527157     0.068320    -0.136167\n",
      "21      0.920019     1.220687     0.349443     0.278181     0.155032\n",
      "22     -0.845169    -0.638082     0.617364     0.258121    -0.130314\n",
      "23     -0.217857     1.093398    -0.812704     0.626406     0.384082\n",
      "24      0.020379     0.963068    -0.541713    -0.510245    -0.212081\n",
      "25     -0.802179    -0.594826     0.551166     0.302593    -0.108894\n",
      "26      0.171449    -0.579423     0.478663    -0.253848     0.106731\n",
      "27     -0.535070    -0.723144     0.381435    -0.559793     0.849852\n",
      "28     -0.745188    -0.627212     0.548125     0.373910    -0.127938\n",
      "29     -0.787084    -0.585373     0.568530     0.333269    -0.129057\n",
      "..           ...          ...          ...          ...          ...\n",
      "114     0.658251    -0.603458     0.699553    -0.387540    -0.268618\n",
      "115     1.088734     0.390908     0.615527     0.583085    -0.018174\n",
      "116    -0.685653     0.781342     0.442731    -0.342793     0.323906\n",
      "117    -0.420527    -0.650076     0.450429     0.038124     0.283489\n",
      "118    -0.971501    -0.610922    -0.423675    -0.365956     0.114228\n",
      "119     0.784633    -0.490270     0.552837    -0.259991    -0.229652\n",
      "120     0.546580     0.942072    -0.354570    -0.513183    -0.621515\n",
      "121    -0.526074    -0.663445    -0.590731    -0.562321     0.521082\n",
      "122    -0.445136    -0.708173     0.477421     0.015815     0.274997\n",
      "123    -0.388265    -0.638644     0.419074     0.068173     0.301548\n",
      "124     0.705892    -0.472846     0.485452    -0.804940     0.329373\n",
      "125     1.165836    -0.127804    -0.646046     0.444823    -0.082774\n",
      "126    -1.035576     0.835862    -0.362821     0.127483    -0.539856\n",
      "127     0.901761    -0.316570     0.455962    -0.203297    -0.185563\n",
      "128    -0.498159     0.832359    -0.554241     0.380727     0.308906\n",
      "129    -0.377821     0.940150    -0.636921     0.448801     0.333114\n",
      "130     1.104684    -0.241821     0.383830     0.385855     0.227553\n",
      "131    -0.504163    -0.760278     0.521227    -0.048405     0.278131\n",
      "132     1.283106    -0.084986     0.214359     0.657565     0.250213\n",
      "133    -0.447419    -0.669932     0.459377    -0.012966     0.310706\n",
      "134    -0.509454    -0.768653     0.529171    -0.061418     0.278738\n",
      "135     1.101046    -0.212870     0.374524     0.366811     0.239464\n",
      "136     0.724153    -0.429225     0.457421    -0.875734     0.367727\n",
      "137     0.854873    -0.287958     0.334717    -0.869887     0.439116\n",
      "138    -0.726922    -0.559030     0.510010     0.389771    -0.110693\n",
      "139    -0.800938    -0.530298    -0.397260     0.220508    -0.407963\n",
      "140    -0.340013    -0.678536     0.388372     0.136748     0.295968\n",
      "141     0.724430    -0.579705    -0.275448    -0.310881    -0.618983\n",
      "142    -0.934349     0.879454     0.518647     0.247752    -0.202780\n",
      "143     0.768987     0.195194     0.796217    -0.139249    -0.455639\n",
      "\n",
      "[144 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Apply PCA by fitting the good data with only two dimensions\n",
    "pca = PCA(n_components=5).fit(X_train)\n",
    "\n",
    "# TODO: Transform the good data using the PCA fit above\n",
    "reduced_data = pca.transform(X_train)\n",
    "\n",
    "# TODO: Transform log_samples using the PCA fit above\n",
    "#pca_samples = pca.transform(log_samples)\n",
    "\n",
    "# Create a DataFrame for the reduced data\n",
    "reduced_data = pd.DataFrame(reduced_data, columns = ['Dimension 1', 'Dimension 2', 'Dimension 3',\n",
    "                                                    'Dimension 4','Dimension 5'])\n",
    "\n",
    "print (reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 18 features per sample; expecting 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-9c546db105ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'log_loss score for Logistic Regression with no parameter tuning:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlr_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduced_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-80-9c546db105ce>\u001b[0m in \u001b[0;36mlr_\u001b[1;34m(features_train, labels_train, features_test, labels_test)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclf_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclf_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf_lr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'log_loss score for Logistic Regression with no parameter tuning:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1334\u001b[0m         \u001b[0mcalculate_ovr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_class\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ovr\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcalculate_ovr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1336\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1337\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1338\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m         \"\"\"\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[1;32m--> 305\u001b[1;33m                              % (X.shape[1], n_features))\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m         scores = safe_sparse_dot(X, self.coef_.T,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 18 features per sample; expecting 5"
     ]
    }
   ],
   "source": [
    "# try to push the reduced data into classifier\n",
    "\n",
    "def lr_(features_train,labels_train, features_test, labels_test):\n",
    "    \n",
    "    clf_lr = LogisticRegression() \n",
    "    clf_lr.fit(features_train, labels_train)\n",
    "    pred=clf_lr.predict_proba(features_test)\n",
    "\n",
    "    print ('log_loss score for Logistic Regression with no parameter tuning:', log_loss(labels_test, pred))\n",
    "\n",
    "lr_(reduced_data, y_train, X_test, y_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(train_values_final.columns, model.feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "sorted_feats = sorted((v,k) for k,v in feats.items())\n",
    "\n",
    "print (sorted_feats)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
